---
layout: post
title: "USA Could Win By Rolling Back AI Export Controls"
date: 2025-01-28
categories:
 - ai
 - engineering
 - geopolitics
 - export-controls
 - china
 - policy
 - hardware
image: https://cdn.pixabay.com/photo/2017/09/01/12/51/china-2704112_960_720.jpg
# social_image: /images/bash-v-powershell.png
is_draft: false
use_mermaid: true
---

This might sound crazy to just about everyone, but I think Trump could maintain an AI lead for
the United States by immediately rolling back Biden-era export controls on AI chips, like the
NVIDIA H100. Hear me out!

First, let's set the stage — **DeepSeek cheated!** Sort of.

_Note: If you haven't heard about R1, [catch up here][r1]._

# US AI Chip Export Controls
In October '22, the Biden administration introduced [export controls][exp] intended to **hamper
China**'s progress on AI development. In practical terms, it prevented Chinese companies from
buying [H100 chips][h100] which are designed to perform massive matrix & tensor operations that
are **critical for training advanced AI**.

NVIDIA released [H800 chips][h800-intro] to [comply with][h800] these export regulations. The relevant
areas were:

* **Reduction in FLOPS** — In practice, this only reduced floating point operations per second 
    (FLOPS) for big 64-bit integers. This greatly impacts scientific applications, but machine
    learning has used smaller 32-bit or 16-bit numbers. DeepSeek used 8-bit numbers to conserve 
    bandwidth further.
* **Half Bandwidth** — This proved to be the most restrictive. AI clusters are thousands of 
    GPUs large, so total performance largely hinges on network bandwidth.

DeepSeek trained R1 using a cluster of H800s (hacked, read on) but serves it in their app and public
API using **Huawei 910Cs**, a Neural Processing Unit (NPU). The 910Cs work fine for serving because
you don't need massive inter-networking for serving as long as the model fits onto a single chip.


## How DeepSeek Skirted Export Controls
During training, the bandwidth contstraint was truly a burden. But DeepSeek engineers were
resourceful and found a workaround.

NVIDIA chips use a high level language called CUDA, which looks a bit like C++, that's what 
most people program GPUs with. CUDA code is compiled into NPX, which is low-level assembler code;
still human readable but very slow and difficult to program in. NPX is then just-in-time translated into machine
code as it executes.

DeepSeek engineers [discovered][h800] that the bandwidth constraint is implemented inside the CUDA
compiler. They could skirt around the restriction by writing NPX code directly. Development
takes a little longer, but it enables them to operate a cluster of H800s at nearly the **same
compute efficiency as H100s**.


### Huawei Is Happy To Help
Yes, obviously Huawei is very happy with this arrangement. They have an interconnect protocol
in development that would enable customers like DeepSeek to build the large AI training clusters
needed to train models like R1 and remain competitive. It also launches them into the global
market as a real NVIDIA competitor.

Huawei needs a customer **to co-develop with**. It's nearly impossible to engineer and build something
to serve massive scale without first having massive scale to test on. DeepSeek has massive scale
and [is happy to help][x].


# Trump: Rollback Export Controls!
What if Trump rolled back Biden's export controls?

NVIDIA has the **best AI chips** in the world. NVIDIA knows the most important metric: 
Total Cost of Ownership, i.e. power consumption per compute, and other chips can't compete here. 
Not only H100s, but NVIDIA just released
[B200s][b200] which have even better compute denisty & power per compute. Furthermore, Google
has their TPUs which are specifically designed for AI workloads, and for the last decade they've
been using AI to [design and optimize TPU generations][tpu]. And then there's ASICs like [Groq][groq] &
[Cerebras][cere] as well as NPUs from AMD, Qualcomm and others.

In other words, Huawei is up against **stiff competition**. Both near-term and long-term. It therefore 
behooves DeepSeek to avoid investing too deeply in Huawei. A co-development partnership would be
a huge investment, a long-term drag on productivity (they're actually a hedge fund, not an AI lab).

If Trump immediately rolled back export controls, it would hit Huawei at a critical moment. Right
as they need to acquire a co-development partner, DeepSeek would be incentivized NOT to enter
into such a relationship and instead stick with NVIDIA & other leading technologies. In other words
it would _**confuse China's effort**_ to [invest in AI infrastructure][invest].

That in turn would **destabilize** Huawei's path to dominance in the East and maintain the US edge,
at least for the foreseeable future.


## Would This Work?
It's hard to say for sure if it would work, there's a lot of variables. But clearly the export controls aren't
slowing Chinese progress, so it can't hurt to try, right?





 [r1]: /blog/2025/01/25/r1
 [h800-intro]: https://lenovopress.lenovo.com/lp1814-thinksystem-nvidia-h800-pcie-gen5-gpu
 [h800]: https://www.storagereview.com/news/how-deepseek-r1-overcame-hardware-limitations-to-deliver-ai-breakthroughs
 [h100]: https://www.weforum.org/videos/what-is-h100-gpu-chip-ai-nvidia/
 [exp]: https://www.csis.org/analysis/updated-october-7-semiconductor-export-controls
 [x]: https://x.com/dorialexander/status/1884167945280278857?s=46&t=ftkDjGBpGPr2-yTN2CCUYg
 [b200]: https://www.nvidia.com/en-us/data-center/dgx-b200/
 [tpu]: https://cloud.google.com/transform/ai-specialized-chips-tpu-history-gen-ai
 [groq]: https://groq.com/
 [cere]: https://cerebras.ai/
 [invest]: https://www.scmp.com/economy/china-economy/article/3277506/chinas-state-owned-firms-splash-1-trillion-yuan-emerging-hi-tech-industries
