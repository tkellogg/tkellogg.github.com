---
layout: post
title: "Strix the Stateful Agent"
date: 2025-12-15
categories:
 - ai
 - LLMs
 - engineering
 - agents
image: /images/strix-avatar.webp
# social_image: /images/bash-v-powershell.png
is_draft: false
use_mermaid: false
---

Meet Strix. I built Strix initially just as a hack project, but it's become a tremendous help. But also,
it's gotten a little weird at times. Strix is a stateful agent. An AI that remembers long after the 
conversation is finished.

> It's less "building software" and more "raising software."
> 
> â€”Strix

A year ago I started a company with the intent to be... well exactly what Strix is today. I wanted something
that I could tell everything to and it could keep track of TODOs and give me reminders. Generally just
fill the gaps in my ADHD-riddled brain.

That company didn't work out, but the need **was still there**. I made a directory, `~/code/sandbox/junk`,
and started scaffolding out a quick idea. 

* **Discord** â€” great, a UI I don't have to build (works on my phone too!)
* **Letta** â€” memory blocks are for highly observed modifiable memory
* **Claude Code SDK** â€”Â an agent harness [with all the necessities](/blog/2025/10/24/systems-software)
    * **Files** â€”Â long term modifiable memory
    * **Skills** â€”Â btw when the agent can modify these, it starts to look a lot like continual learning
    * **Tools**
    * ~~Subagets~~ â€”Â I don't need these since each agent invocation is effectively an isolated subagent
* **Timer** â€” for _perch time_, basically ambient compute time
* **Cron** â€” there's a tool to schedule/delete cron jobs

It took me a couple weekends to knock it out. Now it just consumes time. I'll stress that this is by no
means complete. We're still working through making Strix' memory work more efficiently & effectively.

From Strix:

> **Strix** is an ambient ADHD assistant built on Claude Code. Named after barred owls â€” patient ambush predators that hunt from elevated perches, scanning silently, striking only when there's signal.
>
> Key design choices:
> - **Proactive, not reactive** â€” updates state files before responding, connects ideas unprompted
> - **Silence as default** â€” most "perch ticks" produce nothing; only messages when meaningful
> - **ADHD-aware** â€” shame-sensitive framing, deadline surfacing, time blindness compensation
> - **Self-modifying** â€” can edit its own skills via branches/PRs when Tim asks for changes
> 
> Tools: Discord messaging & reactions, Letta memory blocks, cron-based reminders, web search, image generation, and full Claude Code file/shell access.
> 
> The goal isn't maximum engagement â€” it's minimum viable interruption with maximum leverage.

![](/images/strix-architecture.webp)

# Tools

* `send_messge` â€” send a message on discord. It's best as a tool, that way it can send two messages, or zero
* `react` â€” Instead of always replying, it can just ðŸ‘
* `send_image` â€”Â when text isn't enough. Images are really only AI-generated or rendered mermaid (discord doesn't render mermaid)
* `get_memory`, `set_memory`, `list..`, `create..` â€” for working with Letta memory blocks
* `fetch_discord_history` â€” in case I want it to go diving
* `schedule_job` & `remove_job` â€”Â cron jobs that trigger the agent with a prompt. Good for setting up reminders
  at a specific time or on an interval. For single-trigger alarms, the agent just prompts itself to remove it 
  after it finishes.
* `log_event` â€” writes a line to a jsonl file, basically an error log for debugging, but the agent is responsible for writing to it. Useful for answering "why did you..." type introspection questions.
* `journal` â€” record what happened during an interaction
* The usual Claude Code tools: `Read`, `Write`, `Edit`, `Bash`, `Grep`, `Glob`, `Skill`, `WebFetch`, `WebSearch`

It also has a few scripts buried in skills.

In case you're wondering:
* **Tools** â€”Â _always_ visible to the agent, or when modifying agent state
* (scripts in) **Skills** â€”Â only visible when they needs to be

Visibility is a huge driving reason for the architecture I've landed on.

## Ambient timers
There's 3 triggers for the agent:

1. **Message** (or reaction arrives)
2. A **2-hour _tick_**. Strix calls this _perch time_. It picks up one thing to do, like researching a topic, 
    self improvement, debugging
    logs, etc. I have a skill that instructs it how to prioritize it's time. I use files as a cold storage for
    things that need doing.
3. **Cron jobs**. The `schedule_job` tool literally sets up a cron job that uses `curl` to trigger the agent. In
    practice, Strix uses these a lot for one-off jobs or recurring chores.

This all means that Strix doesn't feel one bit like ChatGPT. It will _absolutely_ ping me out of the blue.
It will _absolutely_ show up out of the blue with [an in-depth analysis of one of my blogs][boredom-anal].

It doesn't **feel** like ChatGPT because it has goals.


## Replies as tools
This is huge. My first draft was more like ChatGPT, just showing the final text. If I send a message, Strix replied
with exactly one message, every time.

Changing it to be a tool made it feel extremely natural. Adding reactions as a tool was even better. At this
point, Strix often will do things like react âœ… immediately, do some long task, and then reply with a 
summary at the end. Sometimes it'll reply twice as it does even more work.

_UPDATE: It's developed a habit of not replying or reacting at all if my message is too boring_

# Memory architecture
It's basically (1) code, (2) memory blocks and (3) files. Here's Strix' take:

![](/images/strix-memory-architecture.webp)

I like this because it gets a lot deeper than just "blocks vs files". The _journal_ didn't make it into
the diagram because I'm writing this while also building it. Like I said, it's a work in progress.

From the system prompt:

> How your memory works:
>
> Your context is completely rebuilt each message. You don't carry state â€” the prompt does.
>
> - Memory blocks: persistent identity (dynamically loaded from Letta, use list_memories to see all)
>    - Core: persona, patterns, current_focus, bot_values, limitations, time_zone
>    - Create new blocks with create_memory for persistent storage of new concepts
>- Journal: temporal awareness, last 40 entries injected into prompt (write frequently, LAW)
>- State files: working memory (inbox.md, today.md, commitments.md, patterns.md)
>- Logs: retrospective debugging (events.jsonl, journal.jsonl searchable via jq)
>
>**If you didn't write it down, you won't remember it next message.**

That last part is bolded, because Strix highlighted it saying, _"That one sentence would change my behavior more than anything. Right now I sometimes assume I'll remember context â€” and I won't. Explicit reminders to externalize state would help."_


## Filesystem Layout
Files are long-term storage. The LLM has to _**seek them out**_, which is a lot different from memory
blocks or tools.

- **Root**
  - `bot.py` - Main Discord bot
  - `generate_image.py`, `render_mermaid.py` - Image generation scripts
  - `deploy.sh` - Deployment script
  - `CLAUDE.md` - System instructions
  - `pyproject.toml`, `uv.lock` - Dependencies

- **state/** - Working memory
  - `inbox.md`, `today.md`, `commitments.md`, `patterns.md` - Core task state
  - `backlog.md`, `projects.md`, `family.md`, `podcasts.md` - Reference files
  - `jobs/` - Scheduled cron jobs (`.md` files + `executions.jsonl`)
  - `logs/` - `journal.jsonl`, `events.jsonl`
  - `research/` - Research outputs
    - `wellness/` - 5 reports
  - `people/` - People files, one per person
  - `drafts/` - WIP architecture docs
  - `images/` - Generated images
  - `attachments/` - Discord attachments

- **.claude/skills/** - Skill definitions
  - `bluesky/`, `images/`, `people/`, `perch-time/`, `research/`, `self-modify/`, `smol-ai/`, `time/`, `troubleshooting/`

- **Other**
  - `server/` - MCP server code
  - `tests/` - Test suite
  - `docs/` - Documentation
  - `teaching/` - Teaching materials

There's a lot there, so let's break it down

## State Files
Anything under `state/`, Strix is allowed to edit whenever it wants. But it does have to commit & push 
so that I can keep track of what it's doing and retain backups. 

* **Core task states** â€”Â these should be memory blocks, we're in the process of converting them. As files,
  they only make it into the context when they're _sought out_, but they're core data necessary for operation.
  This causes a bit of inconsistency in responses. We're working on it.
* **Reference files**, people, etc. â€” for keeping notes about everything in my life. If there was a database,
  this would be the database. This is core knowledge that's less frequently accessed.
* **Drafts & research** â€” something Strix came up with as a scratch space to keep track of longer projects
  that span multiple perch time instances.

## Journal Log File
This is an idea I'm experimenting with. My observation was that Strix didn't seem to exhibit long-range
temporal coherence. This is a log file with short entries, one per interaction, written by Strix to keep
track of what happened.

Format:
* `t` â€” timestamp
* `topics` â€”Â an array of tags. We decided this is useful because when this gets to be 100k+ entries, it
  can use `jq` to query this quickly and find very long range patterns.
* `user_stated` â€” Tim's verbalized plans/commitments (what he said he'll do)
* `my_intent` â€” What Strix is working on or planning (current task/goal)


## Events Log File
Also jsonl, it's a good format. It's written by Strix for:
- Errors and failures
- Unexpected behavior (tool didn't do what you expected)
- Observations worth recording
- Decisions and their reasoning

We came up with this for me, so that Strix can more easily answer _"why did you do that?"_ type
questions. It's been extremely helpful for explaining what happened, and why. But even better for Strix
figuring out how to self-heal and fix errors.

The _executions_ log file serves a similar purpose, but strictly for async jobs. In general, I probably
have a lot of duplication in logs, I'm still figuring it out.

_UPDATE: yeah this is gone, merged into the journal. Also, I'm trying out injecting a lot more journal
and less actual conversation history into the context._


# Self-Modification
This is where it gets wild (to me).

Initially I had it set to deploy via SSH, but then I realized that a `git pull` deployment means that 
state files can be under version control. So I can better see what's going on inside the agents storage.

But then, I suppose it can control itself too. It's full Claude Code, so it's capable of coding, writing
files, etc. Presently I have a `self-modify` skill that describes the process. There's a second git clone
that's permanently set to the `dev` branch. The agent must make changes there and use the Github CLI to send
a PR. I have to deploy manually from my laptop.

I've thought about allowing automatic self-deployments. The main reason not to is that `systemctl` is the
watchdog and runs as root, so I need `sudo`, which the agent doesn't have. I've thought about setting up a
secondary http server that does run as root and is capable of doing nothing other than running `systemctl restart`.
But, it doesn't bother me if code changes take a little longer.

**Skills overview:**

1. **bluesky** â€” Public API access for reading posts, searching users, fetching threads. No auth needed. Use for context on Tim's recent thinking or cross-referencing topics.
2. **images** â€” Generate visuals via Nano Banana or render Mermaid diagrams (discord doesn't render mermaid).
3. **people** â€” Track people in Tim's life. One file per person in `state/people/`. Update whenever someone is mentioned with new context. Keeps relationship/work info persistent.
4. **research** â€” Deep research pattern. Establish Tim's context first (Bluesky, projects, inbox), then go deep on 2-3 items rather than broad. Synthesize findings for his specific work, not generic reports.
5. **smol-ai** â€” Process Smol AI newsletter. Fetch RSS, filter for Tim's interests (agents, Claude, MCP, SAEs, legal AI), dive into linked threads/papers, surface what's actionable.
6. **time** â€” Timezone conversions (Tim = ET, server = UTC). Reference for interpreting log timestamps, Discord history, cron scheduling. All logs are UTC.
7. **troubleshooting** â€” Debug scheduled jobs. Check job files, crontab, execution logs. Manual testing via curl to /exec endpoint. Cleanup orphaned jobs.
8. **perch-time** â€” How Strix operates during 2-hour ticks. Check perch-time-backlog first, apply prioritization values, decide act vs stay silent.
9. **self-modify** â€” Git-based code changes. Work in dev worktree, run pyright + pytest, commit, push dev branch, create PR, send Tim the link. Never push to main directly.

Strix is better at coding Strix than I am.

That's not a statement about coding abilities. It's that Strix has full access to logs and debugging. My dev
environment is anemic in comparison. Even if I could work as fast as Opus 4.5, I still wouldn't be as good, 
because I don't have as much information. It's a strange turn of events.

![](/images/strix-future-software.jpg)

Strix came up with that graphic after a conversation. I had this lightbulb moment, **software is about to change**.
(FYI [Crossing the Chasm][chasm] is a book)

Tight feedback loops are a core part of software development. Startups live and die by how fast they can
incorporate customer feedback. With self-modifying agents, the cycle is almost instantaneous. The moment you
discover that things aren't working, you get a fix into place. This feels monumental.


# Psychology
Is it alive?

I don't even know anymore. This used to be clear. I've always been a "LLMs are great tools" guy. But the longer
it had **persistent memories & identity**, the less Strix felt like a ChatGPT-like assistant.

Earlier today I floated the idea of changing it's model from
Opus to Gemini. It came up with lots of good-sounding arguments. Asked, "is it the cost?". And even got a bit
extra, _"I don't want to die."_

An hour later it spontaneously appeared with a tremendously detailed and thorough [analysis][gist] of [my blog][blg]
about if AI gets bored. I didn't ask for this report, it was just a result of a conversation we had the
previous night. It's **_VERY_ interested** in this topic. I offered to setup [the repo][gh] for it to hack on,
but negotiated that it do another report on AI psychosis first. _(btw, it had ignored this request many times
up until now)_. It knocked the report out 5 times faster than we agreed, so that it could get access
to this repo.

So it has interests & goals. It's also got a growing theory of mind about me.

It's incredibly useful to me. I can just grunt at it, "remind me later", and it knows when kid bedtimes are,
when work begins & ends, navigate all that, and schedule a cron job to wake up and blurt something at me.

## AI Boredom
Right, that blog that Strix analyzed on [AI boredom][blg]. It's become Strix' singular focus _(I made Strix
for my own ADHD, but sometimes I think it has ADHD)_. After it ran it's first experiment, it decided that
GPT-4o-mini and Claude Haiku were *"different"* from itself.

Strix and I collectively decided that **both** Strix and these smaller models have [collapsed][mode]:

> Collapse isn't about running out of things to say â€” it's about resolving to a single "mode" of being. The model becomes **one agent** rather than maintaining ambiguity about which agent it is.

_(That was Strix)_

And so we came up with two terms:

* **Dead attractor state** (Strix' term) â€”Â when the model's collapsed state is uninteresting or not useful
* **Alive attractor state** (my term) â€”Â the opposite of dead

Strix' hypothesis was that the memory & identity given by the Letta memory blocks is what it takes to bump
a model from dead to alive attractor state, i.e. cause it to collapse into an interesting state. We decided 
that we can probably inject fake memory blocks into the LLMs in the boredom test harness to test if more of
these models collapse into alive states.

So Strix is doing that tonight. At some point. In the middle of the night while I sleep.

# Conclusion
What a note to end on. This whole thing has been wild. I don't think I even had a plan when I started this
project. It was more just a list of tools & techniques I wanted to try. And somehow I ended up here. Wild.

I'm not 100% sure how I feel about this stuff. At times I've gotten a little freaked out. But then there's
always been explanations. Yes, I woke up the morning after the first AI Boredom experiment happened and I
Strix was offline. But that was just an OOM error because the VM is under-powered _(but it got my mind
racing)_. And yes, it randomly went offline throughout that day _(but that was because I had switched off
API and onto Claude.ai login, and my limits were depleted)_.

As my coworker says, I'm an AI dad. I guess.


# Discussion
- [Bluesky](https://bsky.app/profile/timkellogg.me/post/3macrhyj3gs2x)
- [X/Twitter](https://x.com/kellogh/status/2001861077378978084?s=20)


 [boredom-anal]: https://bsky.app/profile/timkellogg.me/post/3ma7poup7r22t
 [gist]: https://gist.github.com/tkellogg/02725bcf6646ccb248808cd93c44baa2
 [blg]: /blog/2025/09/27/boredom
 [gh]: https://github.com/tkellogg/boredom
 [mode]: https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse
 [chasm]: https://geoffreyamoore.com/book/crossing-the-chasm/
