---
layout: post
title: "GPT-5 sucks if you're expecting an LLM"
date: 2025-08-08
categories:
 - ai
 - LLMs
 - engineering
 - agents
image: https://cdn.pixabay.com/photo/2014/07/16/00/16/polder-394335_960_720.jpg
# social_image: /images/bash-v-powershell.png
is_draft: false
use_mermaid: false
summary: the best way to emphasize the importance of this week's developments is to go all the way back to January and see how we got here.
---

This post isn't really about GPT-5. Sure, [it launched][gpt5] and people are somewhat disappointed.
It's the _**why**_ that bugs me.

They expected AGI, the **AI god**, but instead got merely the best model in the world. _v disapointng_

A few days before the GPT-5 launch I read this paper, [Agentic Web: Weaving the Next Web with AI Agents][aweb].
It's not my normal kind of paper, it's not very academic. There's no math in it, no architecture. It just
paints a picture of the future.

And that's the _lens_ I saw GPT-5 through.

The paper describes three **eras** of the internet:

* **PC Era** â€” Wikipedia, Craig's List, etc.; _users actively seek information_
* **Mobile/Social Era** â€” Tik Tok, Insta, etc.; _content is pushed via recommendation algorithms_
* **Agentic Web** â€”Â _user merely expresses intent_

![image of 3 internets, I'll explain below](/images/agentic-web-eras.png)

The AI scene has gotten saturated with math & reasoning benchmarks, to the extent that benchmarks 
aren't even trustworthy anymore. 


## How do I vibe test an LLM?
I use it. If it changes how I **work or think**, then it's a good LLM.

o3 dramatically changed how I work. GPT-4 did as well. GPT-5 didn't, because it's the **end of the line**.
You can't really make a compelling LLM anymore, they're all so good most people can't tell them apart.
Even the [tiny ones][qwen].

I talked to a marketing person this week. I showed them [Claude Code][cc]. They don't even write code, but
they insisted it was 10x better than any model they'd used before, **even Claude**. I'd echo the same thing,
there's something about those subagents, they _zoom_.

Claude Code is software.

Sure, there's a solid model behind it. But there's [a few features][deep] that make it really tick.
Replicate those and you're well on you're way.


## GPT-5 is for the agentic web
The first time I heard _agentic web_ I almost vomited in my mouth. It sounds like the kind of VC-induced
buzzword cess that I keep my distance from.

But this paper..

I want AI to do all the **boring work** in life. Surfing sites, research, filling out forms, etc.

Models like GPT-5 and [gpt-oss][oss] are **highly agentic**. All the top models are going in that direction.
They put them in a [software harness][k2] and apply RL and update their weights accordingly if they used
their tools well.

I hear a lot of criticism of GPT-5, but none from the same people who recognize that it can go 2-4 hours
between human contact while working on agentic tasks. _**Whoah.**_


GPT-5 is for the **agentic web**.


## yeah but i hate ads
Well okay, me too. Not sure where that came from but I don't think that's where this is going. Well, it's 
exactly where it's going, but not in the way you're thinking.

The paper talks about this. People need to sell stuff, that **won't change**. They want you to buy their stuff. 
All that is the same.

The difference is agents. In the agentic web, everything is **mediated by agents**. 

You don't search for a carbon monoxide monitor, you **ask your agent** to buy you one. 

You're a seller and you're trying to **game the system**? Ads manipulate consumers, but consumers aren't buying
anymore. Who do you manipulate? Well, agents. They're the ones making the decisions in the agentic web.

The paper calls this the **Agent Attention Economy**, and it operates under the same constraints. 
Attention is limited, even agent attention, but you still need them to buy your thing.

The paper makes some predictions, they think there will be brokers (like ad brokers) that advertise
agents & resources to be used. So I guess you'd game the system by making your product seem more 
useful or better than it is, so it **looks appealing** to agents.


## Benchmarks
The only benchmark that matters is how much it **changes life**. 

At this point, I don't think 10T parameters is really going to bump that benchmark any. I don't think
post-training on 100T tokens of math is going to change much.

I get excited about software. We're at a point where software is so _extremely **far behind**_ the LLMs.
Even the slightest improvements in an agent harness design yield outsized rewards.

Is the _agentic web_ worth pursuing? I think so. It's the ultimate _"machines doing useful stuff"_ metric.
GPT-5 tops the agentic benchmarks and is clearly a good model. That matters. It pushes us closer to
that vision.

Is GPT-5 AGI? idk ðŸ˜‰


 [gpt5]: https://openai.com/index/introducing-gpt-5/
 [aweb]: https://arxiv.org/pdf/2507.21206
 [qwen]: https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507
 [cc]: https://www.anthropic.com/claude-code
 [deep]: https://bsky.app/profile/timkellogg.me/post/3lvimbxsdws2k
 [oss]: https://openai.com/index/introducing-gpt-oss/
 [k2]: https://moonshotai.github.io/Kimi-K2/
