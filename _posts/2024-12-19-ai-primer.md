---
layout: post
title: "AI Engineering Primer"
date: 2024-12-19
categories:
 - ai
 - LLMs
 - engineering
image: https://cdn.pixabay.com/photo/2020/04/24/17/11/river-5087743_1280.jpg
is_draft: false
use_mermaid: false
---

How do you get up to speed with AI engineering? Unfortunately, I don't know of any good consolidated
resources, so I'm going to attempt to make one here. My [first attempt at this][first] focused more on
*what* an AI engineer is and made only a feeble attempt at providing resources to get started. Let's go!

The reason it's difficult is that AI Engineering is so new, it's bleeding edge. People still scoff at the
idea that it's even a title that someone can hold. It's moving so fast that 3 months is roughly equivalent
to a decade, so any resources that might exist become obsolete within a few months.

## Things to Avoid
### Avoid: LangChain
[LangChain][lc] is used pervasively in tutorials. They usually are one of the first to implement a new
prompting technique right after the paper comes out. However, _**nobody I know uses it**_ in production.
Many attempt to, but then replace it with either a langchain competitor or a write their own code.

Instead:
* Hand-roll (has it's own problems, but sometimes it's easier than getting burnt repeatedly by solutions
  that almost work)
* [LlamaIndex](https://www.llamaindex.ai/) — direct langchain competitor
* [griptape](https://www.griptape.ai/) — direct langchain competitor, focused on DAG workflows & tools
* [Haystack](https://haystack.deepset.ai/) — oriented toward search, it's more than a bare vector store
* [DSPy](https://dspy.ai/) — focused on automatic prompt optimization
* [gradio](https://www.gradio.app/) — prototype apps quickly
* Vendor SDKs from Cohere, OpenAI and Anthropic are sometimes quite powerful.

There's a very long list of other good options, both open source & proprietary. The reason LangChain
doesn't work is that the code isn't structured well. It works seamlessly until you run into a case that
they didn't explicitly plan for. Experienced software engineers would say that LangChain doesn't "compose well".

### Avoid: Prompt Influencers
There's no shortage of people on LinkedIn or X that are hawking _"one weird trick"_, the magic prompt,
or in one way or another trying to convince you that there are special words or phrases that magically
make an LLM do your bidding. If it sounds like a salesman trying to sell you something, it's definitely
a salesman trying to sell you something. In fact, they're almost always the sales type, and very rarely have
any sort of engineering experience. Avoid.

### Avoid: Traditional ML People
This is a contentious topic, [I've writen about it](/blog/2024/12/10/ml-liability). They can be an asset,
but beware of blindly taking advice from people who have been deep into traditional pre-LLM machine
learning.


## Boring Advice
### Advice: Use LLMs A Lot
They're both amazingly intelligent and unexpectedly dumb. The only real way to know what you're dealing with
is to use them a lot, for everything. Yes, you do need to get burnt. Just do it in a way that doesn't matter
too much. The goal here is to develop an instinct. You should be able to tell yourself, "if I do _X_ it'll
probably go poorly, but if I rephrase it as _Y_ then I can be confident in what it says".

### Advice: Basic Design Patterns
You should know [RAG][rag] inside & out. [Chain of Thought (CoT)][cot], and the [ReAct pattern][react]. 
Skim the rest of this post for more leads.

### Advice: Buy Apple Silicon
Better yet, get a gaming laptop with an NVIDIA graphics card and Linux. But if not, get a Macbook M1, M2, M3, etc.
series. The main memory & GPU memory is all the same, shared, so you can rock some surprisingly big models,
all local. 

I'm a big advocate of local LLMs, especially for AI engineers. They're worse than the big SOTA models, which
means you learn the sharp edges faster; learn to properly distrust an LLM. Plus, you can send logs with passwords
to a local model, but it's highly unwise to send passwords to OpenAI, Anthropic, or any computer that isn't your 
own.


## Topics
Here are several large areas to learn about. Not all of them will be important to you.

### Topic: New Models
As new models are released, their capabilities increase. As an AI engineer, it's crucial you stay on top
of this. You should know about the pre-training [scaling laws][laws] that have brought LLMs into the 
public's eye.

Ways that models improve:
* Benchmarks — [MMLU][mmlu], [GSM8][gsm8], [HellaSwag][hellaswag], [HumanEval][humaneval], etc. There's
  tons of these and they're always improving and you also shouldn't trust them. They're easily gamed.
  Yet you also have to pay attention and know what they mean. The 
  [open LLM leaderboard](https://huggingface.co/open-llm-leaderboard) has a lot of good info.
* Context width — The size of the input. As this improves, [RAG][rag] becomes easier. But LLMs also get
  [worse at recall with bigger context][ctx-forget], so it's not a slam dunk.
* Reasoning — Models like [o1][o1] do [CoT][cot] natively without prompting to achieve better reasoning
    scores.
* Model size — measured in number of parameters. 13B = 13 billion parameters. Bigger models are generally
    more capable, but smaller models are faster. When you consider [TTC][ttc], [smaller is smarter][sis].
* Modalities — Beyond text, being able to take or emit other modalities like image, video, audio, etc. can
  be a game changer. As of today, Google seems to be leading with [Gemini 2.0][gemini]
* APIs — Occasionally new APIs & features enable wildly new things. e.g. Anthropic's [prompt caching][cache]
  enabled the [Contextual Retrieval][ctxret] pattern for embeddings.

Most of this shows up in blog announcements from the [AI labs](#ai-labs) and announced on X.

### Topic: New Patterns
AI Engineering is still being figured out. If you go back far enough in programming history, languages didn't
even have control structures like `if`/`then` or `for` loops. It took time to figure that stuff out.
We're in a similar spot with AI engineering, where the patterns are still emerging.

Check out [Prompting Guide][guide] for a comprehensive list of current patterns. Also subscribe to 
[Latent Space][latent] and read [Simon Willison][simonw] to keep up to date.

### Topic: Infrastructure
Outside of the [AI labs](#ai-labs), you may want to watch some providers:

* [Cerebras](https://cerebras.ai/) — Fast
* [Groq](https://groq.com/) — Fast (here's a [technical deep dive](https://blog.codingconfessions.com/p/groq-lpu-design) from a distributed systems perspective of how Groq works)
* [Together.AI](https://www.together.ai/) — Recommended place to rent GPUs

Additionally, pay attention to vector stores:

* [Pinecone](https://www.pinecone.io/)
* [Qdrant](https://qdrant.tech/)
* [pgvector](https://github.com/pgvector/pgvector) — Postgres extension to treat it as just another SQL index
  on any table rather than a standalone database. This is a winning strategy, your SQL DB probably already has
  something like this. Use it.
* [Redis](https://redis.io/docs/latest/develop/get-started/vector-database/) — Classic NoSQL database. Watch this,
    though, because it's creator, [antirez][antirez] has been talking about 
    [some wildly different ideas](https://antirez.com/news/144) where the index is more of a plain data structure.
    This might be the key to enabling a lot more patterns, like clustering. Watch antirez' work for updates.

Also, look into edge compute. [Ollama](https://ollama.com/) for personal computers, [vLLM](https://blog.vllm.ai/2023/06/20/vllm.html)
for Linux servers, but also pay attention to [work being done](https://www.reddit.com/r/LocalLLaMA/comments/1ffzsy0/real_world_use_cases_for_small_llm_on_edge_devices/)
to run LLMs on IoT devices and phones.

### Topic: Model Development & Optimization
Generally, **do not do this** unless you know you need to. It's often tempting to try to fine tune, but it's
usually a red herring.

Topics:
* [LoRA](https://huggingface.co/docs/diffusers/en/training/lora) — The cheapest form of fine-tuning
* [Transfer Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)
* [Model distillation](https://openai.com/index/api-model-distillation/)
* [Quantization](https://huggingface.co/docs/optimum/en/concept_guides/quantization) — Make models smaller to take up less memory
* [Memory bandwidth](https://www.reddit.com/r/LocalLLaMA/comments/1brcnps/is_inferencing_memory_bandwidth_limited/) — btw LLMs are so large that typically it's the memory bandwidth that's slowing you down, not the operations/sec.
* [Transformer architecture](https://huggingface.co/learn/nlp-course/en/chapter1/4)
* [Mixture of Experts (MoE)](https://huggingface.co/blog/moe) — I have a feeling this might be a key to further
  innovation soon.

### Topic: Evaluation & Testing
This is quickly evolving and there's unfortunately not much here.

Topics
* Benchmarks (see above)
* [Robustness testing](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/)
* [Mech Interp](https://www.lesswrong.com/posts/tEPHGZAb63dfq2v8n/how-useful-is-mechanistic-interpretability)
    — There's some exciting work being done here to understand how LLMs work on the inside. I'd say 
    [Anthropic](https://www.anthropic.com/research/decomposing-language-models-into-understandable-components)
    is where the [most interesting](https://www.anthropic.com/research/mapping-mind-language-model) stuff happens.
* Compliance — This is a wide topic, definitely check out the [EU AI Act](https://artificialintelligenceact.eu/).
* [Alignment](https://www.anthropic.com/news/core-views-on-ai-safety)

### Topic: Test Time Compute (TTC)
As I'm writing, this is a hot topic. The train time [scaling laws][laws] seem to be fading and the new
promising area is having models "think" longer during inference (see [o1][o1]). This also seems to be a
significant key to agents.

Generally follow [any of the sources below](#sources). The information is spread out.

### Topic: Agents
There's two kinds of perspectives here:

1. "Agent" is anything that uses tools
2. "Agent" is autonomous and interacts with the world

The former isn't very interesting, it's just the [ReAct pattern][react]. The latter is an area of active
research. Within agents you have topics like:

* [Embodied](https://www.humanbrainproject.eu/en/follow-hbp/news/2023/08/09/embodied-ai-bridging-gap-human-cognition/) vs disembodied agents
* [Autonomy](https://www.salesforce.com/agentforce/autonomous-agents/)
* [World models](https://techcrunch.com/2024/12/14/what-are-ai-world-models-and-why-do-they-matter/)
* Agent [Design & Orchestration](https://arxiv.org/abs/2410.21784)

In my experience, present agents are like riding a unicycle. It's possible to make them work, but it takes
a lot of experience to not fall off. The main blocker to having them rolled out more broadly is reasoning
& planning. I think Test Time Compute (TTC) might be part of the puzzle, others are betting on world models.
In reality, it's going to be a bit of everything; the whole field needs to evolve.




## Sources
### Primers
* [Prompting Guide][guide] — Exhaustive coverage of individual topics. All prompting. Very useful for any
    AI engineer.
* [Hugging Face docs](https://huggingface.co/docs) — More oriented toward training new models

The AI Labs's documentation often also has good primers:
* [OpenAI docs](https://platform.openai.com/docs/concepts)
* [Anthropic docs](https://docs.anthropic.com/en/docs/welcome)


### Courses
* [Cohere's LLM University](https://cohere.com/llmu)
* [DeepLearning.AI](https://www.deeplearning.ai/) — "short" courses to know what's out there


### AI Labs
* [OpenAI](https://openai.com/news/)
- [Anthropic](https://www.anthropic.com/news)
- [Hugging Face](https://huggingface.co/blog) – Not the typical lab, focused on open source and small models.
- [Cohere](https://cohere.com/blog) – Caters to enterprises & RAG.
- [Qwen](https://qwenlm.github.io/blog/)
- [DeepSeek](https://www.deepseek.com/)
- [Allen Institute for AI (Ai2)](https://allenai.org/blog)

### People to Watch
* [Simon Willison][simonw] — **READ EVERYTHING SIMON WRITES**, also follow him on one of
    the social platforms: [BlueSky](https://bsky.app/profile/simonwillison.net), [X](https://twitter.com/simonw)
    [Mastodon](https://fedi.simonwillison.net/@simon), [Github](https://github.com/simonw/)
* [Nathan Lambert](https://www.natolambert.com/) — Academic side, mostly RL. [BlueSky](https://twitter.com/natolambert), 
    [X](https://twitter.com/natolambert), [Github](https://github.com/natolambert)
* [antirez][antirez] — creator of Redis, he's doing something interesting around vector indices — [Bluesky](https://bsky.app/profile/antirez.bsky.social), [Github](https://github.com/antirez)
* [Eugene Yan](https://eugeneyan.com/)
* [hamel](https://hamel.dev/) — [Bluesky](https://bsky.app/profile/hamel.bsky.social), [X](https://twitter.com/HamelHusain), [Github](https://github.com/hamelsmu/)
* [Jason Liu](https://jxnl.co/) — [X](https://twitter.com/jxnlco), [Github](https://github.com/jxnl)
* [Chip Huyen](https://huyenchip.com/) — See her [books](https://huyenchip.com/books/) — [Bluesky](https://bsky.app/profile/chiphuyen.bsky.social), [X](https://twitter.com/chipro), [Github](https://github.com/chiphuyen)
* [Lilian Weng](https://lilianweng.github.io/) — [X](https://twitter.com/lilianweng/) [Github](https://github.com/lilianweng)

### News Venues & Newsletters
* [The LocalLlama subredit](https://www.reddit.com/r/LocalLLaMA/) — Great coverage on new models & design patterns
* [Alpha Signal](https://alphasignal.ai/) — breakthroughs, models, repos & research
* [The Rundown AI](https://www.therundown.ai/subscribe)
* [Interconnects](https://www.interconnects.ai/) — More academic. Has substack, podcast
* [Latent Space][latent] — AI Engineer newsletter. More high level.
* [Threat Prompt Newsletter](https://newsletter.threatprompt.com/) — The security perspective



### Github
This is a new one for me, but some highly recommend following people on Github first and then *maybe* follow
individual repos. It's far better to follow people, because then you learn about new repos. Whereas following
repos gets noisy very fast, so only do that when you want to keep close tabs. Look for new repos, new ideas,
and new trends.

See [People to Watch](#people-to-watch) for Github links.


### Huggingface
[Huggingface][(https://huggingface.co/) is like "Github for AI/ML models". Typically, the code for the 
model is kept in Github and the model artifacts are hosted in huggingface. The 
[`transformers`](https://huggingface.co/docs/transformers/index) library makes it very easy to download models
off huggingface and run them, or fine-tune, or disassemble and use just the tokenizer, or steal the attention
layers from an LLM to fine-tune an embedding model, etc.

Also, Huggingface offers inference. So you can host model inference there. For example, the Open LLM Leaderboard
is hosted there, so it's also not limited to just model inference.

Additionally, a lot of papers are posted to huggingface (sometimes instead of arXiv). There seems to be a
social networking aspect to it, where you can comment on papers, follow authors, etc. It's safe to say that
huggingface is a core part of the AI ecosystem. While it's not an AI lab in the traditional sense, it's in
many ways just as critical to AI development, maybe more so.


# Discussion
* The original [bluesky conversation](https://bsky.app/profile/timkellogg.me/post/3ldlobd7uuc2i)

If I forgot something [contact me](/contact), or else use the [Github repo for this blog](https://github.com/tkellogg/tkellogg.github.com/)
to create an issue or PR. Or add to one of the discussion links.


 [first]: /blog/2024/12/09/ai-engineer
 [lc]: https://www.langchain.com/
 [mmlu]: https://paperswithcode.com/dataset/mmlu
 [gsm8]: https://paperswithcode.com/dataset/gsm8k
 [hellaswag]: https://arxiv.org/abs/1905.07830
 [humaneval]: https://paperswithcode.com/sota/code-generation-on-humaneval
 [rag]: https://cloud.google.com/use-cases/retrieval-augmented-generation?hl=en
 [cache]: https://www.anthropic.com/news/prompt-caching
 [ctx-forget]: https://arxiv.org/html/2410.18745v1
 [cot]: https://www.promptingguide.ai/techniques/cot
 [o1]: https://openai.com/index/introducing-openai-o1-preview/
 [ttc]: https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute
 [sis]: https://bsky.app/profile/timkellogg.me/post/3ld4jte5f2s23
 [gemini]: https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/
 [ctxret]: https://www.anthropic.com/news/contextual-retrieval
 [guide]: https://www.promptingguide.ai/
 [latent]: https://newsletter.threatprompt.com/
 [simonw]: https://simonwillison.net/
 [laws]: https://arxiv.org/abs/2001.08361
 [react]: https://www.promptingguide.ai/techniques/react
 [antirez]: https://antirez.com/
