---
layout: thread
title: "Consistency Training"
date: 2025-11-04 12:44:33 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m4sksu3fic2c
likes: 23
reposts: 1
post_count: 2
summary: "Consistency Training  new GDM research notes that both jailbreaking and sycophancy share a common cause — subtle changes in the prompt cause dramatic ..."
similar:
  - url: "/threads/2025-10-31-astonishing-using-fp16-instead-of-bf16-results-in/"
    title: "astonishing: using fp16 instead of bf16 results in more stable training runs ..."
  - url: "/threads/2025-07-08-smollm3-a-highly-detailed-look-into-modern-model/"
    title: "SmolLM3: a highly detailed look into modern model training"
  - url: "/threads/2025-10-01-rlp-reinforcement-learning-in-pre-training-an-n/"
    title: "RLP: Reinforcement Learning in Pre-Training "
---
<div class="thread-post">
<div class="post-text">Consistency Training<br><br>new GDM research notes that both jailbreaking and sycophancy share a common cause — subtle changes in the prompt cause dramatic changes in output<br><br>they address it by training on small prompt changes, expecting the same result<br><br><a href="https://deepmindsafetyresearch.medium.com/consistency-training-could-help-limit-sycophancy-and-jailbreaks-668c184df154" target="_blank" rel="noopener">deepmindsafetyresearch.medium.com/consistency-...</a></div>
<a href="https://deepmindsafetyresearch.medium.com/consistency-training-could-help-limit-sycophancy-and-jailbreaks-668c184df154" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">deepmindsafetyresearch.medium.com</div>
<div class="embed-title">Consistency Training Could Help Limit Sycophancy and Jailbreaks</div>
<div class="embed-description">Authors: Alex Irpan* and Alex Turner*, Mark Kurzeja, David Elson, and Rohin Shah</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>23</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">this is self-supervised learning<br><br>any prompt/response pair can be the seed, then use an LLM to rewrite<br><br>methods like this scale well because they can get ahead of new edge cases by simply training longer</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>