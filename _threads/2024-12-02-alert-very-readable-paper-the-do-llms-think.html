---
layout: thread
title: "ğŸš¨ Alert: Very Readable Paper ğŸš¨"
date: 2024-12-02 13:01:59 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lcd6nqwcuc2i
likes: 46
reposts: 7
post_count: 5
summary: "ğŸš¨ Alert: Very Readable Paper ğŸš¨  The â€œdo LLMs think?â€ question always bugged me because I have no idea what that means. This paper focuses narrowly on,..."
similar:
  - url: "/threads/2025-06-10-when-two-llms-debate-both-think-theyll-win-abso/"
    title: "When two LLMs debate, both think theyâ€™ll win"
  - url: "/threads/2025-11-02-llms-can-report-their-own-experience-the-most-con/"
    title: "LLMs can report their own experience"
  - url: "/threads/2025-11-01-fascinating-paper-it-explores-how-llms-take-diff/"
    title: "fascinating paper â€” it explores how LLMs take different sides on various geop..."
---
<div class="thread-post">
<div class="post-text">ğŸš¨ Alert: Very Readable Paper ğŸš¨<br><br>The â€œdo LLMs think?â€ question always bugged me because I have no idea what that means. This paper focuses narrowly on, â€œdo LLMs learn **how to do** thingsâ€.<br><br>Unlike most ML/AI paper, itâ€™s easy to read and understand WHY<br><a href="https://arxiv.org/abs/2411.12580" target="_blank" rel="noopener">arxiv.org/abs/2411.12580</a></div>
<a href="https://arxiv.org/abs/2411.12580" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">arxiv.org</div>
<div class="embed-title">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</div>
<div class="embed-description">The capabilities and limitations of Large Language Models have been sketched out in great detail in recent years, providing an intriguing yet conflicting picture. On the one hand, LLMs demonstrate a g...</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>46</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">The paper is about procedural knowledge, or the knowledge of a process or procedure.<br><br>People have described LLMs as â€œjust doing next token predictionâ€, which presumably means itâ€™s all just retrieval. This paper shows (conclusively imo) that is not the case, the LLM actually learns the math process</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>4</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Their methods are cRaZy. They found a way to directly attribute which documents (e.g. web page or PDF from the training data set) that the LLM used to produce an answer<br><br>lemme just pause here an marvel at how cool that is</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Since they took this approach, it means they can rather (imo) irrefutably prove the result<br><br>For reasoning problems, they showed that the answer actually was in the training dataset, but the LLM chose not to use it, instead opting for similar math problems that showed the process</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">The paper is truly one of the greats. Every time I had a â€œhold on ğŸ¤”â€ reaction, the very next paragraph answered my question. Over and over.<br><br>Give it a read! For real, not just notebooklm, this is one you can make it through (but maybe skip the math section)</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>4</span>
</div>
</div>