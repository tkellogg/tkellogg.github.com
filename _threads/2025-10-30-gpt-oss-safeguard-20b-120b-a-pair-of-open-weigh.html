---
layout: thread
title: "gpt-oss-safeguard 20b & 120b"
date: 2025-10-30 10:48:31 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m4fryrd5ok2w
likes: 38
reposts: 2
post_count: 3
summary: "gpt-oss-safeguard 20b & 120b  a pair of open weights models that let you enforce custom content moderation policies through prompts  they’re reasoning..."
similar:
  - url: "/threads/2025-08-05-gpt-oss-openais-open-weights-model-120b-20b-v/"
    title: "gpt-oss, OpenAI's open weights model"
  - url: "/threads/2025-08-08-my-personal-take-on-gpt-5-and-llms-in-general-is-t/"
    title: "my personal take on GPT-5 and LLMs in general is that we need to see a lot mo..."
  - url: "/threads/2025-08-25-starting-with-k2-several-large-agentic-coding-m/"
    title: "Starting with K2, several large “agentic coding” models weren’t trained as re..."
---
<div class="thread-post">
<div class="post-text">gpt-oss-safeguard 20b & 120b<br><br>a pair of open weights models that let you enforce custom content moderation policies through prompts<br><br>they’re reasoning models, so you get a CoT explanation, not just a classification<br><br><a href="https://openai.com/index/introducing-gpt-oss-safeguard/" target="_blank" rel="noopener">openai.com/index/introd...</a></div>
<a href="https://openai.com/index/introducing-gpt-oss-safeguard/" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">openai.com</div>
<div class="embed-title">Introducing gpt-oss-safeguard</div>
<div class="embed-description">New open safety reasoning models (120b and 20b) that support custom safety policies.</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>38</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">this feels like the first content moderation model that i’d actually consider using<br><br>1. it only looks for what i want it to look for <br>2. explanations<br><br>the normal approach is non-prompted, trained for a very static set of classes</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>9</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">also, this is the first LLM that i’m aware of that separates control & data channels — it takes the prompt & the conversation as two separate inputs<br><br>this has always been the right way to approach prompt injection, in my mind</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>6</span>
</div>
</div>