---
layout: thread
title: "Apparently OpenAI plans on releasing “Onion” next week, potentially as GPT-5...."
date: 2025-12-03 12:57:48 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m73j3ak3mk27
likes: 23
reposts: 3
post_count: 3
summary: "Apparently OpenAI plans on releasing “Onion” next week, potentially as GPT-5.2 or GPT-5.5  Shallotpeat = a huge new model, fixing pretraining bugs in ..."
similar:
  - url: "/threads/2025-03-31-openai-is-releasing-a-very-good-reasoning-model/"
    title: "OpenAI is releasing a “very good” reasoning model in the coming weeks, open w..."
  - url: "/threads/2025-12-04-openai-trained-a-gpt-5-variant-to-admit-when-it-to/"
    title: "OpenAI trained a GPT-5 variant to admit when it took shortcuts"
  - url: "/threads/2025-08-05-gpt-oss-openais-open-weights-model-120b-20b-v/"
    title: "gpt-oss, OpenAI's open weights model"
---
<div class="thread-post">
<div class="post-text">Apparently OpenAI plans on releasing “Onion” next week, potentially as GPT-5.2 or GPT-5.5<br><br>Shallotpeat = a huge new model, fixing pretraining bugs in GPT-4.5<br><br>Onion = lessons learned from shallotpeat applied to an efficient GPT-5 base (i think)<br><br><a href="https://www.theinformation.com/articles/openai-developing-garlic-model-counter-googles-recent-gains" target="_blank" rel="noopener">www.theinformation.com/articles/ope...</a></div>
<a href="https://www.theinformation.com/articles/openai-developing-garlic-model-counter-googles-recent-gains" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">www.theinformation.com</div>
<div class="embed-title">OpenAI Developing ‘Garlic’ Model to Counter Google’s Recent Gains</div>
<div class="embed-description">OpenAI, which in recent weeks has appeared to fall behind Google in AI development, is fighting back with a new large language model codenamed Garlic.Last week, OpenAI’s chief research officer Mark Ch...</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>23</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">all of this seems triggered directly by Google’s Gemini 3 Pro<br><br>Gemini proved that pre-training scaling is not dead. Word is that while OpenAI is absurdly good at post-training, Google is good at pre-training and post-training gains just fall into their lap</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>11</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">i think sama’s bet is that if they can catch up on their pre-training game, openai will utterly dominate. and if they don’t, Google will<br><br>so yeah, pretraining isn’t dead, not at all</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>13</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>