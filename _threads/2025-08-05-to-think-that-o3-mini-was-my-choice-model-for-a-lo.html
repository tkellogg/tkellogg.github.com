---
layout: thread
title: "to think that o3-mini was my choice model for a long time, and now gpt-oss:20..."
date: 2025-08-05 21:11:36 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lvompqkhrc2m
likes: 44
reposts: 2
post_count: 2
summary: "to think that o3-mini was my choice model for a long time, and now gpt-oss:20B is basically equivalent and runs on my laptop ðŸ¤¯"
similar:
  - url: "/threads/2025-08-09-1-what/"
    title: "1) What"
  - url: "/threads/2025-10-27-minimax-open-sources-m2-this-model-has-been-shaki/"
    title: "MiniMax open sources M2"
  - url: "/threads/2025-08-01-gpt5-is-such-a-great-coding-model/"
    title: "GpT5 iS sUcH a GrEaT cOdInG mOdEl"
---
<div class="thread-post">
<div class="post-text">to think that o3-mini was my choice model for a long time, and now gpt-oss:20B is basically equivalent and runs on my laptop ðŸ¤¯</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>44</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">comparison</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreiedi5pihnutucushoyd6fo2dhapndfijynvvqch6oqcm55phhjqpa@jpeg" alt="Grouped bar chart with five subplots comparing model accuracy across different tasks and benchmarks. Each subplot shares the same x-axis: models o3, o3-mini, o4-mini, gpt-oss-120b, and gpt-oss-20b. Color-coded bars represent different models.

Top row:
	1.	AIME 2024 (Competition Math, With Tools)
	â€¢	o3: 95.2%
	â€¢	o3-mini: 87.3%
	â€¢	o4-mini: 98.7%
	â€¢	gpt-oss-120b: 96.6%
	â€¢	gpt-oss-20b: 96.0%
	2.	AIME 2025 (Competition Math, With Tools)
	â€¢	o3: 98.4%
	â€¢	o3-mini: 86.5%
	â€¢	o4-mini: 99.5%
	â€¢	gpt-oss-120b: 97.9%
	â€¢	gpt-oss-20b: 98.7%
	3.	GPQA Diamond (PhD Science Questions, Without Tools)
	â€¢	o3: 83.3%
	â€¢	o3-mini: 77.0%
	â€¢	o4-mini: 81.4%
	â€¢	gpt-oss-120b: 80.1%
	â€¢	gpt-oss-20b: 71.5%

Bottom row:
	4.	HLE (Expert-Level Questions)
	â€¢	o3 (tools): 24.9%
	â€¢	o3-mini (no tools): 13.4%
	â€¢	o4-mini: 17.7%
	â€¢	gpt-oss-120b (tools): 19.0%
	â€¢	gpt-oss-120b (no tools): 14.9%
	â€¢	gpt-oss-20b (tools): 17.3%
	â€¢	gpt-oss-20b (no tools): 10.9%
	5.	MMLU (College-level Exams)
	â€¢	o3: 93.4%
	â€¢	o3-mini: 87.0%
	â€¢	o4-mini: 93.0%
	â€¢	gpt-oss-120b: 90.0%
	â€¢	gpt-oss-20b: 85.3%

Overall, o4-mini performs strongest on AIME and MMLU. o3 has the highest HLE accuracy with tools. GPT-based models trail behind across most tasks." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>11</span>
</div>
</div>