---
layout: thread
title: "Google’s TPU v7: Ironwood"
date: 2025-04-09 15:07:35 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lmfbe6q6u22l
likes: 21
reposts: 8
post_count: 2
summary: "Google’s TPU v7: Ironwood  A massive hardware leap  - 4,614 TFLOPS per chip - 256 or 9,216 chips per pod - 192 GB HBM(emory) per chip @ 7.2 Tbps - ICI..."
similar:
  - url: "/threads/2025-09-12-nvidias-moat-just-got-bigger-the-rubin-ctx-is-fo/"
    title: "NVIDIA’s moat just got bigger"
  - url: "/threads/2025-09-02-nvidia-stock-is-about-to-surge-a-vldb-paper-from/"
    title: "NVIDIA stock is about to surge"
  - url: "/threads/2025-10-15-more-movement-to-agentic-behavior-computer-use/"
    title: "more movement to agentic behavior & computer use"
---
<div class="thread-post">
<div class="post-text">Google’s TPU v7: Ironwood<br><br>A massive hardware leap<br><br>- 4,614 TFLOPS per chip<br>- 256 or 9,216 chips per pod<br>- 192 GB HBM(emory) per chip @ 7.2 Tbps<br>- ICI (inter-chip interconnect) @ 1.2 Tbps<br>- SparseCore for ultra large embeddings<br><br><a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/" target="_blank" rel="noopener">blog.google/products/goo...</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreicwiiup7zzqi64wunyns7cwzbs2bf77gpzl7gnvmznby5462qpzge@jpeg" alt="The image is a bar graph titled “TPUv7 Peak FLOPS Performance”, comparing the peak floating-point operations per second (FLOPS) of various Tensor Processing Unit (TPU) versions. The x-axis represents different TPU versions, while the y-axis indicates peak FLOPS performance, measured in teraflops (TFLOPS). Each TPU version is represented by a vertical bar, with the height corresponding to its performance.

The bars show a clear progression in performance across TPU generations:
	•	TPUv4: Approximately 275 TFLOPS. ￼
	•	TPUv5e: Around 197 TFLOPS, indicating a slight decrease from v4. ￼
	•	Trillium (TPUv6): Significant increase to approximately 926 TFLOPS.
	•	TPUv7: Further improvement, reaching around 1,000 TFLOPS.

The graph highlights the substantial advancements in TPU performance, especially with the introduction of Trillium (TPUv6) and TPUv7. These newer versions demonstrate Google’s commitment to enhancing AI processing capabilities, with TPUv7 achieving a notable increase in peak FLOPS performance." class="post-image" loading="lazy">
<div class="image-alt">The image is a bar graph titled “TPUv7 Peak FLOPS Performance”, comparing the peak floating-point operations per second (FLOPS) of various Tensor Processing Unit (TPU) versions. The x-axis represents different TPU versions, while the y-axis indicates peak FLOPS performance, measured in teraflops (TFLOPS). Each TPU version is represented by a vertical bar, with the height corresponding to its performance.

The bars show a clear progression in performance across TPU generations:
	•	TPUv4: Approximately 275 TFLOPS. ￼
	•	TPUv5e: Around 197 TFLOPS, indicating a slight decrease from v4. ￼
	•	Trillium (TPUv6): Significant increase to approximately 926 TFLOPS.
	•	TPUv7: Further improvement, reaching around 1,000 TFLOPS.

The graph highlights the substantial advancements in TPU performance, especially with the introduction of Trillium (TPUv6) and TPUv7. These newer versions demonstrate Google’s commitment to enhancing AI processing capabilities, with TPUv7 achieving a notable increase in peak FLOPS performance.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>21</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>8</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Google is on a steep upward trajectory<br><br>Gemini 2.5 is now the favored coding model, above sonnet-3.7, and now with TPU v7, they feel like the only provider that can really hold up under expanding compute demands</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>