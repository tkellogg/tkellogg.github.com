---
layout: thread
title: "the owners of TikTok scandalously release:"
date: 2025-09-09 15:47:06 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lyg2vpts222w
likes: 32
reposts: 4
post_count: 3
summary: "the owners of TikTok scandalously release:  REER: a learning method that exposes the logic that led to a good result  Booty: when shaken properly elic..."
similar:
  - url: "/threads/2024-12-24-a-new-paper-dropped-from-deepmind-deliberation-in/"
    title: "A new paper dropped from DeepMind: Deliberation in Latent Space via Different..."
  - url: "/threads/2025-07-24-the-irony-here-is-that-grok-3-4-are-the-only-model/"
    title: "the irony here is that Grok 3-4 are the only models to violate this"
  - url: "/threads/2025-11-04-i-added-this-to-my-agentsmd-file-text-in-alt-an/"
    title: "I added this to my AGENTS.md file (text in alt) and it seems to work well"
---
<div class="thread-post">
<div class="post-text">the owners of TikTok scandalously release:<br><br>REER: a learning method that exposes the logic that led to a good result<br><br>Booty: when shaken properly elicits creative writing<br><br>ASS: (they couldn’t get an acronym to work, but i’m sure they tried)<br><br><a href="https://huggingface.co/papers/2509.06160" target="_blank" rel="noopener">huggingface.co/papers/2509....</a></div>
<a href="https://huggingface.co/papers/2509.06160" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">huggingface.co</div>
<div class="embed-title">Paper page - Reverse-Engineered Reasoning for Open-Ended Generation</div>
<div class="embed-description">Join the discussion on this paper page</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>32</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>4</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">seriously this is very cool! all jokes aside<br><br>with REER, they discover a more scalable alternative to RL. instead of teaching *why* behavior leads to a good result, it *deconstructs* what led to a correct result<br><br>it feels like the unsupervised RL that we need</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreihgacepgksct6rhivzhpszzn4nn2trwqxsls4r4hm7s4lo5bypz54@jpeg" alt="The image is a diagram contrasting forward reasoning approaches with a new method called Reverse-Engineered Reasoning (REER).

Diagram Breakdown:
	1.	Left Side – Build Reasoning “forward”:
	•	User Request →
Arrows lead to two costly methods:
	•	Reinforcement Learning (RL): Illustrated with a maze, reward checkmarks, and X marks for failures.
	•	Costly Distillation: Shown with chain links and logos of AI companies/models.
	•	These represent standard approaches that struggle in open-ended domains due to lack of clear reward signals.
	2.	Middle – Deep Reasoning:
	•	A gear system and a human brain icon represent deep reasoning processes.
	3.	Right Side – Recover Reasoning “backward”:
	•	A hooded figure with a bug icon symbolizes REverse-Engineered Reasoning (REER).
	•	REER works backwards from Source QA Pairs (illustrated with icons for questions, answers, money, science, and communication).

⸻

Caption (verbatim):

Figure 1 (Left) Existing methods attempt to build deep reasoning “forwards” for a user request through trial-and-error (RL) or costly distillation, which falter in open-ended domains that lack clear, verifiable reward signals. (Right) We propose a third path for teaching deep reasoning, REverse-Engineered Reasoning (REER). REER works “backwards”, recovering plausible human-like thought process from known-good outputs in open-source Question-Answer (QA) pairs.


" class="post-image" loading="lazy">
<div class="image-alt">The image is a diagram contrasting forward reasoning approaches with a new method called Reverse-Engineered Reasoning (REER).

Diagram Breakdown:
	1.	Left Side – Build Reasoning “forward”:
	•	User Request →
Arrows lead to two costly methods:
	•	Reinforcement Learning (RL): Illustrated with a maze, reward checkmarks, and X marks for failures.
	•	Costly Distillation: Shown with chain links and logos of AI companies/models.
	•	These represent standard approaches that struggle in open-ended domains due to lack of clear reward signals.
	2.	Middle – Deep Reasoning:
	•	A gear system and a human brain icon represent deep reasoning processes.
	3.	Right Side – Recover Reasoning “backward”:
	•	A hooded figure with a bug icon symbolizes REverse-Engineered Reasoning (REER).
	•	REER works backwards from Source QA Pairs (illustrated with icons for questions, answers, money, science, and communication).

⸻

Caption (verbatim):

Figure 1 (Left) Existing methods attempt to build deep reasoning “forwards” for a user request through trial-and-error (RL) or costly distillation, which falter in open-ended domains that lack clear, verifiable reward signals. (Right) We propose a third path for teaching deep reasoning, REverse-Engineered Reasoning (REER). REER works “backwards”, recovering plausible human-like thought process from known-good outputs in open-source Question-Answer (QA) pairs.


</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>33</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">and it works!<br><br>they made a tiny 8B model that holds up well against many large MoE models</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreihe4evqa7y7c3rivjkvihtmtcbc5mldikrl6dja37jb2obbeocoli@jpeg" alt="The image is a table labeled Table 1, showing a performance comparison of different models on LongBench (LB), HelloBench (HB), and WritingBench (WB). The note above the table states that DeepWriter-8B, an 8B model fine-tuned from scratch, shows competitive performance against leading proprietary models and significantly outperforms other open-source models in its class.

⸻

Table Content:

Model	Base Model	LB	HB-A	HB-B	WB-A	WB-B	WB-C	WB-D	WB-E	WB-F
GPT-4o	-	83.1	83.7	87.6	74.40	73.42	74.38	77.91	75.86	78.08
Claude 3.5	-	89.3	82.9	88.3	59.05	57.68	56.32	59.36	62.00	67.70
Claude 3.7	-	97.8	83.9	93.2	78.24	77.93	76.51	79.37	79.26	80.88
LongWriter-8B	Llama3.1-8b	76.5	80.1	82.6	57.97	53.92	49.08	52.08	52.99	52.08
DeepWriter-8B	Qwen3-8b	91.28	82.64	87.48	72.20	71.76	70.57	70.57	73.65	72.29


⸻

Key Observations:
	•	Claude 3.7 leads in raw scores for LB (97.8) and HB-B (93.2).
	•	DeepWriter-8B consistently performs at a very strong level across all WritingBench (WB) categories, beating LongWriter-8B by a wide margin and coming close to proprietary models.
	•	GPT-4o is balanced across all tasks with solid performance.
	•	Claude 3.5 underperforms significantly on WB tasks compared to Claude 3.7.
	•	DeepWriter-8B shows clear gains over LongWriter-8B and holds its ground against GPT-4o and Claude family models, particularly excelling in WB-B through WB-F.
" class="post-image" loading="lazy">
<div class="image-alt">The image is a table labeled Table 1, showing a performance comparison of different models on LongBench (LB), HelloBench (HB), and WritingBench (WB). The note above the table states that DeepWriter-8B, an 8B model fine-tuned from scratch, shows competitive performance against leading proprietary models and significantly outperforms other open-source models in its class.

⸻

Table Content:

Model	Base Model	LB	HB-A	HB-B	WB-A	WB-B	WB-C	WB-D	WB-E	WB-F
GPT-4o	-	83.1	83.7	87.6	74.40	73.42	74.38	77.91	75.86	78.08
Claude 3.5	-	89.3	82.9	88.3	59.05	57.68	56.32	59.36	62.00	67.70
Claude 3.7	-	97.8	83.9	93.2	78.24	77.93	76.51	79.37	79.26	80.88
LongWriter-8B	Llama3.1-8b	76.5	80.1	82.6	57.97	53.92	49.08	52.08	52.99	52.08
DeepWriter-8B	Qwen3-8b	91.28	82.64	87.48	72.20	71.76	70.57	70.57	73.65	72.29


⸻

Key Observations:
	•	Claude 3.7 leads in raw scores for LB (97.8) and HB-B (93.2).
	•	DeepWriter-8B consistently performs at a very strong level across all WritingBench (WB) categories, beating LongWriter-8B by a wide margin and coming close to proprietary models.
	•	GPT-4o is balanced across all tasks with solid performance.
	•	Claude 3.5 underperforms significantly on WB tasks compared to Claude 3.7.
	•	DeepWriter-8B shows clear gains over LongWriter-8B and holds its ground against GPT-4o and Claude family models, particularly excelling in WB-B through WB-F.
</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>25</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>