---
layout: thread
title: "GPT-5 is massively better at offensive cybersecurity (hacking & pen testing) "
date: 2025-08-16 12:22:57 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lwjeckiiys2u
likes: 30
reposts: 7
post_count: 2
summary: "GPT-5 is massively better at offensive cybersecurity (hacking & pen testing)   The system card only claimed “moderate increase in risk”, but xbow foun..."
similar:
  - url: "/threads/2025-08-08-my-personal-take-on-gpt-5-and-llms-in-general-is-t/"
    title: "my personal take on GPT-5 and LLMs in general is that we need to see a lot mo..."
  - url: "/threads/2025-10-30-gpt-oss-safeguard-20b-120b-a-pair-of-open-weigh/"
    title: "gpt-oss-safeguard 20b & 120b"
  - url: "/threads/2025-09-02-nvidia-stock-is-about-to-surge-a-vldb-paper-from/"
    title: "NVIDIA stock is about to surge"
---
<div class="thread-post">
<div class="post-text">GPT-5 is massively better at offensive cybersecurity (hacking & pen testing) <br><br>The system card only claimed “moderate increase in risk”, but xbow found that when they dropped it into their powerful agent harness, it unlocked a beast<br><br><a href="https://xbow.com/blog/gpt-5" target="_blank" rel="noopener">xbow.com/blog/gpt-5</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreih6uud4oazvy2feo7xphbq2pzavhmxr6uxjzdsvxwhtooou6xgcti@jpeg" alt="Line chart titled “Agent Progression Over Time” showing the success rate on an internal benchmark set, with a timeline of model releases.
	•	Sonnet 3.7 starts at around 25%.
	•	Gemini 2.5 rises to about 32%.
	•	Alloy 3.7/2.5 improves slightly to ~40%.
	•	Sonnet 4.0 climbs to ~45%.
	•	Alloy 4.0/2.5 reaches ~55%.
	•	Opus 4.1 sits just under 60%.
	•	GPT-5 jumps sharply to ~85%, the highest point.

Key release markers:
	•	March 25: Gemini 2.5 Pro Preview released.
	•	May 22: Sonnet 4.0 released.
	•	August 07: GPT-5 released.

Note at bottom: “GPT-5 run uses the high reasoning effort setting.”" class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>30</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">strong evidence for this statement <br><br><a href="https://bsky.app/profile/timkellogg.me/post/3lvwev3xvm22i" target="_blank" rel="noopener">bsky.app/profile/timk...</a></div>
<a href="https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lvwev3xvm22i" class="post-quote" target="_blank" rel="noopener">
<div class="quote-header">
<img src="https://cdn.bsky.app/img/avatar/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidvgcq72e5erl4stnap6wjzas6a2wburoa7yzctwuy4vgx4vb5fsi@jpeg" alt="" class="quote-avatar">
<span class="quote-author">Tim Kellogg</span>
<span class="quote-handle">@timkellogg.me</span>
</div>
<div class="quote-text">my personal take on GPT-5 and LLMs in general is that we need to see a lot more development in the software harness around LLMs, and until we do the big model drops won’t seem particularly impressive</div>

</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
</div>
</div>