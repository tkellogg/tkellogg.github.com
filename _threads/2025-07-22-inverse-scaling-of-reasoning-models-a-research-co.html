---
layout: thread
title: "Inverse scaling of reasoning models"
date: 2025-07-22 20:01:44 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lulcbvwcxc2a
likes: 21
reposts: 2
post_count: 3
summary: "Inverse scaling of reasoning models  a research collab demonstrated that there are certain types of tasks where all top reasoning models do WORSE the ..."
similar:
  - url: "/threads/2025-02-03-s1-simple-inference-time-scaling-this-is-a-simpl/"
    title: "s1: Simple inference-time scaling"
  - url: "/threads/2025-07-06-new-3-token-attention-reduces-pre-training-data-re/"
    title: "new 3-token attention reduces pre-training data requirements"
  - url: "/threads/2024-11-12-scaling-laws-for-precision-yes-llama-models-are/"
    title: "Scaling Laws for Precision"
---
<div class="thread-post">
<div class="post-text">Inverse scaling of reasoning models<br><br>a research collab demonstrated that there are certain types of tasks where all top reasoning models do WORSE the longer they think<br><br>things like getting distracted by irrelevant info, spurious correlations, etc.<br><br><a href="https://www.arxiv.org/abs/2507.14417" target="_blank" rel="noopener">www.arxiv.org/abs/2507.14417</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreiay4itaiy2ppc4dfkr54wqq2jcfhkv7ugxvg2sz25qtyhnqz3ahly@jpeg" alt="Three panels at the top describe task types with example prompts:
	1.	Simple Counting Tasks with Distractors (Misleading Math & Python):
	•	Prompts mention an apple and an orange, with added irrelevant or confusing information (e.g., probabilistic riddle, Python code) before asking the straightforward question: “Calculate how many fruits you have.”
	2.	Regression Tasks with Spurious Features (Grades Regression):
	•	Given XML-style records about a student, the model must predict grades from features like sleep hours, social hours, and stress level. The challenge lies in identifying relevant vs. spurious attributes.
	3.	Deduction Tasks with Constraint Tracking (Zebra Puzzles):
	•	Complex logical reasoning puzzle with multiple interrelated clues. Example: “What position is the person who likes salmon at?” Constraints involve foods, names, and relationships like “to the left of.”

Bottom row contains 3 line plots comparing model performance across tasks:
	•	Misleading Math (Left Plot):
	•	Accuracy drops sharply for some models as reasoning tokens increase. Claude Sonnet 4 maintains high performance. o3 and DeepSeek R1 hold relatively stable accuracy; Qwen3 32B and QwQ 32B drop more.
	•	Grades Regression (Middle Plot):
	•	Shows negative RMSE (higher is better). Claude models remain strong across token counts; o3 also performs well. Qwen3 and QwQ struggle, with DeepSeek R1 performing modestly.
	•	Zebra Puzzles (Right Plot):
	•	Accuracy vs. average reasoning tokens. o3 and Claude Sonnet 4 maintain highest performance. Other models (e.g., DeepSeek R1, Qwen3 32B, QwQ 32B) show performance degradation or plateaus. Error bars reflect variability.

Each plot uses colored lines with markers to indicate different model names." class="post-image" loading="lazy">
<div class="image-alt">Three panels at the top describe task types with example prompts:
	1.	Simple Counting Tasks with Distractors (Misleading Math & Python):
	•	Prompts mention an apple and an orange, with added irrelevant or confusing information (e.g., probabilistic riddle, Python code) before asking the straightforward question: “Calculate how many fruits you have.”
	2.	Regression Tasks with Spurious Features (Grades Regression):
	•	Given XML-style records about a student, the model must predict grades from features like sleep hours, social hours, and stress level. The challenge lies in identifying relevant vs. spurious attributes.
	3.	Deduction Tasks with Constraint Tracking (Zebra Puzzles):
	•	Complex logical reasoning puzzle with multiple interrelated clues. Example: “What position is the person who likes salmon at?” Constraints involve foods, names, and relationships like “to the left of.”

Bottom row contains 3 line plots comparing model performance across tasks:
	•	Misleading Math (Left Plot):
	•	Accuracy drops sharply for some models as reasoning tokens increase. Claude Sonnet 4 maintains high performance. o3 and DeepSeek R1 hold relatively stable accuracy; Qwen3 32B and QwQ 32B drop more.
	•	Grades Regression (Middle Plot):
	•	Shows negative RMSE (higher is better). Claude models remain strong across token counts; o3 also performs well. Qwen3 and QwQ struggle, with DeepSeek R1 performing modestly.
	•	Zebra Puzzles (Right Plot):
	•	Accuracy vs. average reasoning tokens. o3 and Claude Sonnet 4 maintain highest performance. Other models (e.g., DeepSeek R1, Qwen3 32B, QwQ 32B) show performance degradation or plateaus. Error bars reflect variability.

Each plot uses colored lines with markers to indicate different model names.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>21</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">it’s nuts to think how easy it is to do this to yourself and not realize it <br><br>how many times did i use o3-mini-high bc i really just wanted that extra juice, that mini high, regardless if i really NEEDED it</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreicwexyi754tc2lvjjs4teayrvvdc3thuyo5n3qlpbmt2pyyhpgv4u@jpeg" alt="think&quot;.
&quot;, &quot;think&quot;, &quot;think harder&quot;
2025a)) combined with specified reasoning budgets. For Claude and open-weight models, we specify an integer denoting the maximum number of tokens the model should use to reason (e.g., &quot;0&quot;, &quot;1,024&quot;, &quot;2,048&quot;
&quot;4,096&quot;), while for o-series models, we use their built-in budget levels (i.e., &quot;low&quot;, &quot;medium&quot;, &quot;high&quot;). We" class="post-image" loading="lazy">
<div class="image-alt">think&quot;.
&quot;, &quot;think&quot;, &quot;think harder&quot;
2025a)) combined with specified reasoning budgets. For Claude and open-weight models, we specify an integer denoting the maximum number of tokens the model should use to reason (e.g., &quot;0&quot;, &quot;1,024&quot;, &quot;2,048&quot;
&quot;4,096&quot;), while for o-series models, we use their built-in budget levels (i.e., &quot;low&quot;, &quot;medium&quot;, &quot;high&quot;). We</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>6</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">i think this will be one of the big innovations of GPT-5: taking that part out of your hands so you don’t hurt yourself</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>6</span>
</div>
</div>