---
layout: thread
title: "Muon optimizer learns more from rare data than Adam"
date: 2025-10-03 16:04:05 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m2ch26pvos2w
likes: 26
reposts: 3
post_count: 2
summary: "Muon optimizer learns more from rare data than Adam  i need to dig deeper. i think the industry is coalescing on:  - Adam is faster - Muon is more sta..."
similar:
  - url: "/threads/2025-11-26-summary-hes-got-a-divergent-view-of-agi-were/"
    title: "Summary — He's got a divergent view of AGI"
  - url: "/threads/2024-12-26-not-enough-is-being-said-about-deepseeks-multi-to/"
    title: "not enough is being said about DeepSeek’s multi token prediction (MTP)"
  - url: "/threads/2025-01-26-a-researcher-on-x-explains-why-rl-alone-didnt-wor/"
    title: "a researcher on X explains why RL alone didn’t work before "
---
<div class="thread-post">
<div class="post-text">Muon optimizer learns more from rare data than Adam<br><br>i need to dig deeper. i think the industry is coalescing on:<br><br>- Adam is faster<br>- Muon is more stable<br>- now, Muon learns rare data better<br><br>i wonder if that’s why K2 has that vibe that it has<br><br><a href="https://arxiv.org/abs/2509.26030" target="_blank" rel="noopener">arxiv.org/abs/2509.26030</a></div>
<a href="https://arxiv.org/abs/2509.26030" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">arxiv.org</div>
<div class="embed-title">Muon Outperforms Adam in Tail-End Associative Memory Learning</div>
<div class="embed-description">The Muon optimizer is consistently faster than Adam in training Large Language Models (LLMs), yet the mechanism underlying its success remains unclear. This paper demystifies this mechanism through th...</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>26</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">btw both Kimi K2 & GLM >=4.5 were trained with Muon<br><br>maybe others, not sure. Adam was classically the preferred optimizer. Now, there’s no clear preference anymore. trade-offs all the way down</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>5</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>