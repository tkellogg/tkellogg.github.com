---
layout: thread
title: "openai researcher posts on X (not a blog or paper) about a model they have th..."
date: 2025-07-19 11:58:28 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lucvuyvn722s
likes: 29
reposts: 2
post_count: 8
summary: "openai researcher posts on X (not a blog or paper) about a model they have that can win the International Math Olympiad  you can’t verify anything he ..."
similar:
  - url: "/threads/2025-07-22-gemini-deepthink-also-won-gold-on-the-internationa/"
    title: "Gemini DeepThink also won gold on the International Math Olympiad"
  - url: "/threads/2025-03-31-openai-is-releasing-a-very-good-reasoning-model/"
    title: "OpenAI is releasing a “very good” reasoning model in the coming weeks, open w..."
  - url: "/threads/2025-11-06-closed-source-now-lags-open/"
    title: "closed source now lags open"
---
<div class="thread-post">
<div class="post-text">openai researcher posts on X (not a blog or paper) about a model they have that can win the International Math Olympiad<br><br>you can’t verify anything he says, but he’s totally telling the truth</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreiarzmw4ffdzw5yoerhv5ugys55n4klzfziy32gfojpagwz3gre2ay@jpeg" alt="Alexander Wei
@alexwei_
8/N Btw, we are releasing GPT-5 soon, and we're excited for you to try it. But just to be clear: the IMO gold LLM is an experimental research model. We don't plan to release anything with this level of math capability for several months." class="post-image" loading="lazy">
<div class="image-alt">Alexander Wei
@alexwei_
8/N Btw, we are releasing GPT-5 soon, and we're excited for you to try it. But just to be clear: the IMO gold LLM is an experimental research model. We don't plan to release anything with this level of math capability for several months.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>29</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">tbf he did post the work for a few cherry picked problems <br><br><a href="https://github.com/aw31/openai-imo-2025-proofs" target="_blank" rel="noopener">github.com/aw31/openai-...</a><br><br>i think the interesting part here (if true) is they used general RL, not math-specific RL, combined with test-time compute scaling</div>
<a href="https://github.com/aw31/openai-imo-2025-proofs" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">github.com</div>
<div class="embed-title">GitHub - aw31/openai-imo-2025-proofs</div>
<div class="embed-description">Contribute to aw31/openai-imo-2025-proofs development by creating an account on GitHub.</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">when they say there using test time scaling, they’re **really** using it</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreifzkzfkirtrnexbesgiisbh7i3yhmkypadtyaaz5ccducttlgxjna@jpeg" alt="Noam Brown @polynoamial
Also this model thinks for a *long* time. 01 thought for seconds. Deep Research for minutes.
This one thinks for hours. Importantly, it's also more efficient with its thinking. And there's a lot of room to push the test-time compute and efficiency further." class="post-image" loading="lazy">
<div class="image-alt">Noam Brown @polynoamial
Also this model thinks for a *long* time. 01 thought for seconds. Deep Research for minutes.
This one thinks for hours. Importantly, it's also more efficient with its thinking. And there's a lot of room to push the test-time compute and efficiency further.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>11</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">afaict they’re not using Lean or any other proof assistant at runtime, they say “without tools”<br><br>seems like a big hit to Gary Marcus’ belief in neurosymbolic reasoning</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>11</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">RL does better when you give partial credit, that was R1’s finding<br><br>this theory suggests they trained on extremely hard problems and created extremely tailored ways of giving partial credit, to incentivize good behavior, in a way that’s far too specific to scale<br><br>the innovation is scaling it</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidvgtharm7emcc35gkpy5bcjtbdxg5pghptavhtypicocp4ltzj3y@jpeg" alt="Teknium (e/^)
@Teknium1

My best guess:
Rubrics + LLM Judge - Atomize each point in the ground truth proof and check against the model output
My guess on how they made this scalable - as before it was not, humans had to meticulously craft them, is they trained or did something to make very good rubrics generated for each specific problem or its answer.

QT
Alexander Wei
@alexwei_ • 5h
5/N Besides the result itself, I am excited about our approach: We reach this capability level not via narrow, task-specific methodology, but by breaking new ground in general-purpose reinforcement learning and test-time compute scaling." class="post-image" loading="lazy">
<div class="image-alt">Teknium (e/^)
@Teknium1

My best guess:
Rubrics + LLM Judge - Atomize each point in the ground truth proof and check against the model output
My guess on how they made this scalable - as before it was not, humans had to meticulously craft them, is they trained or did something to make very good rubrics generated for each specific problem or its answer.

QT
Alexander Wei
@alexwei_ • 5h
5/N Besides the result itself, I am excited about our approach: We reach this capability level not via narrow, task-specific methodology, but by breaking new ground in general-purpose reinforcement learning and test-time compute scaling.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>8</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">i’m not sure if that’s true — Noam said they didn’t train only on Math problems<br><br>i suppose this really is a generic method though. if you can create highly detailed and customized rubrics for math, maybe you can do it for any domain</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>8</span>
</div>
</div>
<div class="thread-post">
<div class="time-elapsed">3 hours later</div>
<div class="post-text">similar take, verifier is the innovation, but this one says there was basically no RL (instead of all RL)<br><br>verifiers are like that. they can be used for test time reasoning, or for RL training</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreifobexgpfci6hmq35cq2i5jqi7hhjoat2awlpjvtizlcordxqbhsi@jpeg" alt="wh@@nrehiew_•3h
Takeaways + (guesses):
1) This is likely a multi agent system. So it isn't a single reasoner thinking for a million tokens in one go
2) (This likely doesn't use much training compute if at all)
3) They have a general purpose verifier beyond just rule based final answer checking. (seed thinking verifier style on proofs/cot directly)
4) They think this verifier (even though likely has the lIm as a judge form) is extremely hard to hack" class="post-image" loading="lazy">
<div class="image-alt">wh@@nrehiew_•3h
Takeaways + (guesses):
1) This is likely a multi agent system. So it isn't a single reasoner thinking for a million tokens in one go
2) (This likely doesn't use much training compute if at all)
3) They have a general purpose verifier beyond just rule based final answer checking. (seed thinking verifier style on proofs/cot directly)
4) They think this verifier (even though likely has the lIm as a judge form) is extremely hard to hack</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="time-elapsed">9 hours later</div>
<div class="post-text">interesting example of compression = intelligence <br><br>they must have fine tuned the IMO model to be extremely succinct</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreibpvxcwzjjwq2q4y6i2i4bha2pbenjbsodjrgbe563kvhyq2prcje@jpeg" alt="Dave
@dmvaldman • 50m
••.
A striking thing about OpenAl's IMO gold math model is how terse it is, it really tries to express itself in single tokens. Often breaking the rules of grammar and spelling to do so. They say compression is intelligence. We may be seeing a totally novel way to do compression here!
Some examples:
not divisible by3
(saves a token by not including a space &quot;by 3&quot;)
Let w= circumcircle
(saves a token, w=circumcircle is 5 tokens where including a space on just one side makes it 4 tokens)
Need show also all terms multiple of 3. (saves a token by not pluralizing &quot;multiple&quot;)
And it marks progress using single token words like: perfect, good, full, exactly)" class="post-image" loading="lazy">
<div class="image-alt">Dave
@dmvaldman • 50m
••.
A striking thing about OpenAl's IMO gold math model is how terse it is, it really tries to express itself in single tokens. Often breaking the rules of grammar and spelling to do so. They say compression is intelligence. We may be seeing a totally novel way to do compression here!
Some examples:
not divisible by3
(saves a token by not including a space &quot;by 3&quot;)
Let w= circumcircle
(saves a token, w=circumcircle is 5 tokens where including a space on just one side makes it 4 tokens)
Need show also all terms multiple of 3. (saves a token by not pluralizing &quot;multiple&quot;)
And it marks progress using single token words like: perfect, good, full, exactly)</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>