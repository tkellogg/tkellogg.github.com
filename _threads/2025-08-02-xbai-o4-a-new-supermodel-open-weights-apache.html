---
layout: thread
title: "XBai-o4: a new supermodel"
date: 2025-08-02 21:53:39 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lvh5o6ezok27
likes: 36
reposts: 7
post_count: 6
summary: "XBai-o4: a new supermodel  * Open weights, apache 2 * 32B * beats o3-mini * for TTC they train an extra head as a reward model to do binary classifica..."
similar:
  - url: "/threads/2025-09-24-meta-fair-just-released-cwd-a-dense-32b-code-worl/"
    title: "Meta FAIR just released CWD: a dense 32B code world model"
  - url: "/threads/2025-01-25-huggingface-is-doing-a-fully-open-source-replicati/"
    title: "huggingface is doing a fully open source replication of R1 github.com/hugging..."
  - url: "/threads/2025-10-27-minimax-open-sources-m2-this-model-has-been-shaki/"
    title: "MiniMax open sources M2"
---
<div class="thread-post">
<div class="post-text">XBai-o4: a new supermodel<br><br>* Open weights, apache 2<br>* 32B<br>* beats o3-mini<br>* for TTC they train an extra head as a reward model to do binary classification <br><br>hf: <a href="https://huggingface.co/MetaStoneTec/XBai-o4f" target="_blank" rel="noopener">huggingface.co/MetaStoneTec...</a><br>paper: <a href="https://arxiv.org/abs/2507.01951" target="_blank" rel="noopener">arxiv.org/abs/2507.01951</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreifetolfoem2omschdcgimd7y6zpc3ibg5sb62mxjeum2hhdta34he@jpeg" alt="A side-by-side bar chart compares the performance of three models—XBai o4 (blue), OpenAI-o3-mini (gray), and Claude Opus 4 (yellow)—across two operational modes: Medium Mode and Low Mode. Each mode has results on three benchmarks: AIME24, AIME25, and LiveCodeBench v5.

Medium Mode:
	•	AIME24: XBai o4 (85.4), o3-mini (79.6), Claude Opus 4 (75.7)
	•	AIME25: XBai o4 (77.6), o3-mini (74.8), Claude Opus 4 (75.5)
	•	LiveCodeBench v5: XBai o4 (67.0), o3-mini (66.3), Claude Opus 4 (61.3)

Low Mode:
	•	AIME24: XBai o4 (82.4), o3-mini (60.0), Claude Opus 4 (75.7)
	•	AIME25: XBai o4 (74.8), o3-mini (48.3), Claude Opus 4 (75.5)
	•	LiveCodeBench v5: XBai o4 (66.6), o3-mini (62.0), Claude Opus 4 (61.3)

XBai o4 leads in nearly every category, with particularly strong performance on AIME24 in both modes. Claude Opus 4 closely trails o3-mini in some Medium Mode results but outperforms o3-mini in Low Mode for AIME25." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>36</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">also: who????</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">unbroken huggingface link: <a href="https://huggingface.co/MetaStoneTec/XBai-o4" target="_blank" rel="noopener">huggingface.co/MetaStoneTec...</a></div>
<a href="https://huggingface.co/MetaStoneTec/XBai-o4" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">huggingface.co</div>
<div class="embed-title">MetaStoneTec/XBai-o4 · Hugging Face</div>
<div class="embed-description">We’re on a journey to advance and democratize artificial intelligence through open source and open science.</div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>8</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">it uses a Self-supervised Process Reward Model (SPRM) to grade several reasoning trajectories <br><br>the SPRM is a different model, but mostly not. Same base + 53M for the grading</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreicjyybphn7sjstdfbertytqhn6btfoynw2ipasscspr6ygt4qh4ky@jpeg" alt="Figure showing two parts: the top (a) illustrates the training framework and the bottom (b) illustrates the inference framework for Reflective Generative Models (RGMs).

Top: Training Framework (a)
	•	A Policy Model takes in a sequence of tokens:
	•	Gray = Question/Answer tokens
	•	Yellow = <think> and </think> tokens
	•	Blue = Think process tokens
	•	Orange = Step-tokens
	•	The model’s internal representations (from layers N-1 and N) are fed into two components:
	•	Policy Head, which outputs the final action (e.g. text response) with GRPO loss L_GRPO
	•	SPRM Head, which outputs scores Score_1, ..., Score_n to rank candidate thought processes, optimized by L_SPR
	•	The SPRM Head consists of a linear layer, dropout, and another linear layer applied to a feature vector.

Bottom: Inference Framework (b)
	•	A question Q is processed by the Policy Model, which generates multiple thought sequences: Think_1, Think_k, each paired with a score s_1, s_k from the SPRM Head.
	•	The highest-scoring thought s_j = max(s) is selected.
	•	That thought is fed back into the Policy Model to produce the final answer A.

This framework enables reflection during generation by scoring intermediate “thinking steps” and selecting the most promising one to continue with." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>9</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">it’s safe to say we’re long past Ollama <br><br>with Ollama, it’s gotta be represented as a single gguf execution graph. this double-uses the same weights Matryoshka-style to support as second model running at the same time</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>8</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">the vibe i get is that the OpenAI & DeepMind IMO Gold models also did similar tricks <br><br>is the SPRM the same model? sort of, i guess</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
</div>
</div>