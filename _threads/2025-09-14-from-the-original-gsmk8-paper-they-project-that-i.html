---
layout: thread
title: "from the original GSMK8 paper, they project that it would require a 10 quadri..."
date: 2025-09-14 21:17:37 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lyt7pd7edc2s
likes: 23
reposts: 3
post_count: 4
summary: "from the original GSMK8 paper, they project that it would require a 10 quadrillion parameter model to get an 80% on GSMK8  Gemma 3 4B got 89%"
similar:
  - url: "/threads/2025-01-26-a-researcher-on-x-explains-why-rl-alone-didnt-wor/"
    title: "a researcher on X explains why RL alone didn’t work before "
  - url: "/threads/2025-12-02-dsa-deepseek-sparse-attention-deepseek-32-32/"
    title: "DSA: DeepSeek Sparse Attention"
  - url: "/threads/2025-07-21-kimi-k2-paper-is-out-lessons-1-they-explicitl/"
    title: "Kimi K2 paper is out!"
---
<div class="thread-post">
<div class="post-text">from the original GSMK8 paper, they project that it would require a 10 quadrillion parameter model to get an 80% on GSMK8<br><br>Gemma 3 4B got 89%</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreid5uuwjrmrdnuoet5ht4wwbmey7mtsdlqu2xyne7ahzmjt3g3lhxm@jpeg" alt="for each test problem. Unsurprisingly, we see that the 175B model significantly outperforms the smaller models. Assuming a log-linear trend, we can naively extrapolate these results to estimate that a model with 1016 parameters would be required to reach an 80% solve rate, when using the full GSM8K training set. It is even harder to extrapolate along the data dimension, since performance does not appear to follow a log-linear trend. Nevertheless, it appears likely that the 175B model would require at least two additional orders of magnitude of training data to reach an 80% solve rate." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>23</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">question: what got us here?<br><br>i argue it was data. <br><br>obvs everything played a part, but there’s papers showing as much as multiple orders of magnitude drop in data requirements <br><br>also: we used to get freaked out by synthetic data, we’ve gotten over that now<br><br><a href="https://bsky.app/profile/timkellogg.me/post/3lyt2qxvx5k2s" target="_blank" rel="noopener">bsky.app/profile/timk...</a></div>
<a href="https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lyt2qxvx5k2s" class="post-quote" target="_blank" rel="noopener">
<div class="quote-header">
<img src="https://cdn.bsky.app/img/avatar/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidvgcq72e5erl4stnap6wjzas6a2wburoa7yzctwuy4vgx4vb5fsi@jpeg" alt="" class="quote-avatar">
<span class="quote-author">Tim Kellogg</span>
<span class="quote-handle">@timkellogg.me</span>
</div>
<div class="quote-text">data is more important than algorithms</div>
<div class="quote-images"><img src="https://cdn.bsky.app/img/feed_fullsize/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreick5jclpwgdudkwjzlz3nehjzpif46bqjxabxh7bfjlkcld3vp4km@jpeg" alt="a man saying “yes, you are all wrong”, surrounded by like a thousand people" class="quote-image" loading="lazy"></div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">i think you could also argue that it wouldn’t be possible to jump straight to these levels. not simply difficult, but outright impossible <br><br>so much of what we do these days in training leverages other LLMs</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>9</span>
</div>
</div>
<div class="thread-post">
<div class="post-text"><a href="https://bsky.app/profile/dorialexander.bsky.social/post/3lysrmdc7xk2e" target="_blank" rel="noopener">bsky.app/profile/dori...</a></div>
<a href="https://bsky.app/profile/did:plc:vg3thtvfbgfrr3u6pf6hy3yk/post/3lysrmdc7xk2e" class="post-quote" target="_blank" rel="noopener">
<div class="quote-header">
<img src="https://cdn.bsky.app/img/avatar/plain/did:plc:vg3thtvfbgfrr3u6pf6hy3yk/bafkreibs7ii3ttxu37wi2ljpo3hsj56qityzvgihl4vw6q7uknu3q73aly@jpeg" alt="" class="quote-avatar">
<span class="quote-author">Alexander Doria</span>
<span class="quote-handle">@dorialexander.bsky.social</span>
</div>
<div class="quote-text">Model collapse was actually a remarkable piece of memetic warfare: copyright holders are falling into the trap and in deep denial over the turn to synth.</div>

</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>2</span>
</div>
</div>