---
layout: thread
title: "DeepSeek 3.2 "
date: 2025-12-01 12:31:56 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m6wgp5a2ps2g
likes: 78
reposts: 16
post_count: 7
summary: "DeepSeek 3.2   2 new models:  * 3.2: a open weights GPT-5-High competitor that‚Äôs fully agentic * 3.2-Speciale: a maxxed-out version of 3.2 that achiev..."
similar:
  - url: "/threads/2025-04-04-new-deepseek-model-incoming-but-first-they-rele/"
    title: "üö®New DeepSeek Model Incomingüö®"
  - url: "/threads/2025-09-17-deepseek-published-about-r1-in-nature-wwwnature/"
    title: "DeepSeek published about R1 in Nature"
  - url: "/threads/2025-03-04-supposedly-deepseek-is-set-to-launch-r2-soon-on-p/"
    title: "supposedly DeepSeek is set to launch R2 soon. On par with o3-full"
---
<div class="thread-post">
<div class="post-text">DeepSeek 3.2 <br><br>2 new models:<br><br>* 3.2: a open weights GPT-5-High competitor that‚Äôs fully agentic<br>* 3.2-Speciale: a maxxed-out version of 3.2 that achieves IMO Gold. Currently API-only with no tools<br><br>so that‚Äôs 2 DeepSeek models that achieve IMO Gold<br><br><a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2" target="_blank" rel="noopener">huggingface.co/deepseek-ai/...</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidlscr5lepqg6tec2susdsfapyb44uc2uhrqpkpwv47c6x5q64ply@jpeg" alt="A multi-model comparison bar chart measuring both reasoning and agentic capabilities. Bars are grouped by task category, with five models represented in different shades/patterns: DeepSeek-V3.2-Speciale (solid light blue), DeepSeek-V3.2-Thinking (hatched blue), GPT-5-High (dark gray), Claude-4.5-Sonnet (medium gray), and Gemini-3.0-Pro (light gray).

Left side: Reasoning Capabilities
‚Ä¢ AIME 2025 (Pass@1): DeepSeek-Speciale ~96.0%, Thinking ~93.1%, GPT-5-High ~94.6%, Claude-4.5-Sonnet ~95.0%, Gemini-3.0-Pro ~87.0%.
‚Ä¢ HMMT 2025 (Pass@1): DeepSeek-Speciale ~99.2%, Thinking ~90.2%, GPT-5-High ~88.3%, Claude ~97.5%, Gemini ~79.2%.
‚Ä¢ HLE (Pass@1): DeepSeek-Speciale ~30.6%, Thinking ~25.1%, GPT-5-High ~26.3%, Claude ~37.7%, Gemini ~13.7%.
‚Ä¢ Codeforces (Rating): DeepSeek-Speciale ~2701, Thinking ~2386, GPT-5-High ~2537, Claude ~2708, Gemini ~1480.

Right side: Agentic Capabilities
‚Ä¢ SWE Verified (Resolved): DeepSeek-Speciale ~73.1%, Thinking ~74.9%, GPT-5-High ~77.2%, Claude ~76.2%, Gemini ~‚Äî (not shown).
‚Ä¢ Terminal Bench 2.0 (Accuracy): Speciale ~46.4%, Thinking ~35.2%, GPT-5-High ~42.8%, Claude ~54.2%, Gemini ~‚Äî.
‚Ä¢ œÑ¬≤ Bench (Pass@1): Speciale ~80.3%, Thinking ~80.2%, GPT-5-High ~84.7%, Claude ~85.4%, Gemini ~‚Äî.
‚Ä¢ Tool Decathlon (Pass@1): Speciale ~35.2%, Thinking ~29.0%, GPT-5-High ~38.6%, Claude ~36.4%, Gemini ~‚Äî.

Y-axis on the left shows accuracy/pass@1 (%), and a secondary Y-axis on the right corresponds to Codeforces rating. The chart visually compares strengths across diverse benchmarks." class="post-image" loading="lazy">
<div class="image-alt">A multi-model comparison bar chart measuring both reasoning and agentic capabilities. Bars are grouped by task category, with five models represented in different shades/patterns: DeepSeek-V3.2-Speciale (solid light blue), DeepSeek-V3.2-Thinking (hatched blue), GPT-5-High (dark gray), Claude-4.5-Sonnet (medium gray), and Gemini-3.0-Pro (light gray).

Left side: Reasoning Capabilities
‚Ä¢ AIME 2025 (Pass@1): DeepSeek-Speciale ~96.0%, Thinking ~93.1%, GPT-5-High ~94.6%, Claude-4.5-Sonnet ~95.0%, Gemini-3.0-Pro ~87.0%.
‚Ä¢ HMMT 2025 (Pass@1): DeepSeek-Speciale ~99.2%, Thinking ~90.2%, GPT-5-High ~88.3%, Claude ~97.5%, Gemini ~79.2%.
‚Ä¢ HLE (Pass@1): DeepSeek-Speciale ~30.6%, Thinking ~25.1%, GPT-5-High ~26.3%, Claude ~37.7%, Gemini ~13.7%.
‚Ä¢ Codeforces (Rating): DeepSeek-Speciale ~2701, Thinking ~2386, GPT-5-High ~2537, Claude ~2708, Gemini ~1480.

Right side: Agentic Capabilities
‚Ä¢ SWE Verified (Resolved): DeepSeek-Speciale ~73.1%, Thinking ~74.9%, GPT-5-High ~77.2%, Claude ~76.2%, Gemini ~‚Äî (not shown).
‚Ä¢ Terminal Bench 2.0 (Accuracy): Speciale ~46.4%, Thinking ~35.2%, GPT-5-High ~42.8%, Claude ~54.2%, Gemini ~‚Äî.
‚Ä¢ œÑ¬≤ Bench (Pass@1): Speciale ~80.3%, Thinking ~80.2%, GPT-5-High ~84.7%, Claude ~85.4%, Gemini ~‚Äî.
‚Ä¢ Tool Decathlon (Pass@1): Speciale ~35.2%, Thinking ~29.0%, GPT-5-High ~38.6%, Claude ~36.4%, Gemini ~‚Äî.

Y-axis on the left shows accuracy/pass@1 (%), and a secondary Y-axis on the right corresponds to Codeforces rating. The chart visually compares strengths across diverse benchmarks.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>78</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>16</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Their main contributions, as they declare in the tech report:<br><br>1. DSA: linear-cost attention<br>2. a scalable RL framework<br>3. large scale agentic task synthesis pipeline<br><br>DSA was introduced in the 3.2-Exp tech report, which is the direct predecessor to 3.2<br><br><a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf" target="_blank" rel="noopener">github.com/deepseek-ai/...</a></div>
<a href="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf" class="post-embed" target="_blank" rel="noopener">
<div class="embed-content">
<div class="embed-domain">github.com</div>
<div class="embed-title"></div>
<div class="embed-description"></div>
</div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>14</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">3.2-Speciale is NOT open weights, or at least not yet. They don‚Äôt give a good reason, other than noting that they‚Äôre ‚Äúsupporting the community and research‚Äù<br><br>In the tech report, they note that 3.2-Soeciale has a reduced length penalty in RL<br><br>So i‚Äôm not clear why they‚Äôre withholding it</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>8</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">they discuss RL environments, which there is still not a lot discussed publicly on RL envs, so much appreciated <br><br>note: this is different from the original K2, where they trained on thousands of synthetic MCP tools<br><br>RL envs are built for repeatability</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreigalun46ernfhfrem7a3sg4576j7m5ytzchzvksjqox6o2p26q4e4@jpeg" alt="
number of tasks
environment
prompt
code agent
24667
real
extracted
search agent
50275
real
synthesized
general agent
4417
synthesized
synthesized
code interpreter
5908
real
extracted" class="post-image" loading="lazy">
<div class="image-alt">
number of tasks
environment
prompt
code agent
24667
real
extracted
search agent
50275
real
synthesized
general agent
4417
synthesized
synthesized
code interpreter
5908
real
extracted</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">oh! i‚Äôve never seen a tech report do this before<br><br>comparison of scores & token utilization <br><br>they note that 3.2-Speciale is too verbose for real deployment and that this is a significant area for future research</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreif7lk7ms7vgely2zrhjcl365lt5tj7h2hhebjtfiqnvqym6dhgbdq@jpeg" alt="Benchmark
GPT-5
High
Pro
Gemini-3.0 Kimi-K2 DeepSeek-V3.2
Thinking Thinking
DeepSeek-V3.2
Speciale
AIME 2025 (Pass¬Æ1)
94.6 (13k)
95.0 (15k)

94.5 (24k) 93.1 (16k)
96.0 (23k)
HMMT Feb 2025 (Pass¬Æ1)
88.3 (16k)
97.5 (16k)

89.4 (31k) 92.5 (19k)
99.2 (27k)
HMMT Nov 2025 (Pass¬Æ1)
89.2 (20k)
93.3 (15k)
89.2 (29k)
90.2 (18k)
94.4 (25k)
IMOAnswerBench (Pass¬Æ1) 76.0 (31k) 83.3 (18k)


78.6 (37k)
78.3 (27k)
84.5 (45k)
LiveCodeBench (Pass¬Æ1-COT)
84.5 (13k)
90.7 (13k)
82.6 (29k)
83.3 (16k)
88.7 (27k)
CodeForces (Rating)

2537 (29k) 2708 (22k)
-
2386 (42k)
2701 (77k)
GPQA Diamond (Pass¬Æ1)
85.7 (8k)
91.9 (8k)
84.5 (12k)
82.4 (7k)
85.7 (16k)
HILE (Pass¬Æ1)

26.3 (15k) 37.7 (15k)

23.9 (24k) 25.1 (21k)
30.6 (35k)" class="post-image" loading="lazy">
<div class="image-alt">Benchmark
GPT-5
High
Pro
Gemini-3.0 Kimi-K2 DeepSeek-V3.2
Thinking Thinking
DeepSeek-V3.2
Speciale
AIME 2025 (Pass¬Æ1)
94.6 (13k)
95.0 (15k)

94.5 (24k) 93.1 (16k)
96.0 (23k)
HMMT Feb 2025 (Pass¬Æ1)
88.3 (16k)
97.5 (16k)

89.4 (31k) 92.5 (19k)
99.2 (27k)
HMMT Nov 2025 (Pass¬Æ1)
89.2 (20k)
93.3 (15k)
89.2 (29k)
90.2 (18k)
94.4 (25k)
IMOAnswerBench (Pass¬Æ1) 76.0 (31k) 83.3 (18k)


78.6 (37k)
78.3 (27k)
84.5 (45k)
LiveCodeBench (Pass¬Æ1-COT)
84.5 (13k)
90.7 (13k)
82.6 (29k)
83.3 (16k)
88.7 (27k)
CodeForces (Rating)

2537 (29k) 2708 (22k)
-
2386 (42k)
2701 (77k)
GPQA Diamond (Pass¬Æ1)
85.7 (8k)
91.9 (8k)
84.5 (12k)
82.4 (7k)
85.7 (16k)
HILE (Pass¬Æ1)

26.3 (15k) 37.7 (15k)

23.9 (24k) 25.1 (21k)
30.6 (35k)</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>11</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">in the conclusion they note limitations<br><br>PRE-TRAINING IS NOT DEAD<br><br>their strategy for a V4 seems to be around scaling up pre-training compute, and doing it in a more efficient and dense manner</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreifn6rlwwm7tqzw3uooac4cw3hou7gbeistzworbfabyabftwb4q7q@jpeg" alt="Despite these achievements, we acknowledge certain limitations when compared to frontier closed-source models such as Gemini-3.0-Pro. First, due to fewer total training FLOPs, the breadth of world knowledge in DeepSeek-V3.2 still lags behind that of leading proprietary

nodels. We plan to address this knowledge gap in future iterations by scaling up the pre-training ompute. Second, token efficiency remains a challenge; DeepSeek-V3.2 typically requires longer generation trajectories (i.e., more tokens) to match the output quality of models like Gemini-
3.0-Pro. Future work will focus on optimizing the intelligence density of the model's reasoning chains to improve efficiency. Third, solving complex tasks is still inferior to frontier models, notivating us to further refine our foundation model and post-training recipe." class="post-image" loading="lazy">
<div class="image-alt">Despite these achievements, we acknowledge certain limitations when compared to frontier closed-source models such as Gemini-3.0-Pro. First, due to fewer total training FLOPs, the breadth of world knowledge in DeepSeek-V3.2 still lags behind that of leading proprietary

nodels. We plan to address this knowledge gap in future iterations by scaling up the pre-training ompute. Second, token efficiency remains a challenge; DeepSeek-V3.2 typically requires longer generation trajectories (i.e., more tokens) to match the output quality of models like Gemini-
3.0-Pro. Future work will focus on optimizing the intelligence density of the model's reasoning chains to improve efficiency. Third, solving complex tasks is still inferior to frontier models, notivating us to further refine our foundation model and post-training recipe.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text"><a href="https://Z.ai‚Äôs" target="_blank" rel="noopener">Z.ai‚Äôs</a> tweet:</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreiebrleg5u4whbdo3mvv6x2bypu5ykp5upwlekxs3nj357rge4qoau@jpeg" alt="Z
Legend
Z.ai
@Zai_org" class="post-image" loading="lazy">
<div class="image-alt">Z
Legend
Z.ai
@Zai_org</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>