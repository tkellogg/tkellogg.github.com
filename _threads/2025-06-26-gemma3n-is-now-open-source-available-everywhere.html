---
layout: thread
title: "gemma3n is now open source, available everywhere — huggingface, transformers,..."
date: 2025-06-26 21:39:59 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lsk3nohxjc2i
likes: 22
reposts: 3
post_count: 2
summary: "gemma3n is now open source, available everywhere — huggingface, transformers, gguf, ollama, mlx, etc.  huggingface.co/blog/gemma3n"
similar:
  - url: "/threads/2025-05-20-gemma-3n-the-4b-llm-thats-up-with-sonnet-37-in/"
    title: "Gemma 3n: the 4b LLM that’s up with sonnet-3.7 in chatbot arena"
  - url: "/threads/2025-07-29-yesssss-a-small-update-to-qwen3-30b-a3b-this-has/"
    title: "yesssss! a small update to Qwen3-30B-A3B"
  - url: "/threads/2025-04-28-its-here-a-real-qwen3-model-huggingfacecoqwe/"
    title: "it’s here! a real Qwen3 model "
---
<div class="thread-post">
<div class="post-text">gemma3n is now open source, available everywhere — huggingface, transformers, gguf, ollama, mlx, etc.<br><br><a href="https://huggingface.co/blog/gemma3n" target="_blank" rel="noopener">huggingface.co/blog/gemma3n</a></div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>22</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="time-elapsed">17 hours later</div>
<div class="post-text">i had o3 line up the comparison of gemma 3n with other models of varying sizes</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidmwqfr7iv25ktkiqesukev3yvr452v6fhe22kr6ch4ouknpexpnq@jpeg" alt="Alt text:
Grouped bar chart titled “Benchmark Comparison Across Models.” The x-axis lists seven language models (left → right): Gemma 3-n E4B IT, GPT-4o, Claude 3 Opus, Llama 3.3 70B, Mixtral 8×22B, Llama 3 8B, Phi-3 mini 4B.
For each model there are three adjacent vertical bars:

Model	MMLU Accuracy	MBPP pass@1	HumanEval pass@1
Gemma 3-n E4B IT	~65 %	~64 %	~75 %
GPT-4o	~86 %	~71 %	~86 %
Claude 3 Opus	~89 %	~70 %	~86 %
Llama 3.3 70B	~86 %	~88 %	~88 %
Mixtral 8×22B	~78 %	~64 %	~74 %
Llama 3 8B	~73 %	~73 %	~73 %
Phi-3 mini 4B	~69 %	~70 %	~59 %

The y-axis spans 0 % to 100 %. Taller bars indicate stronger performance; Llama 3.3 70B, GPT-4o, and Claude 3 Opus lead across all three benchmarks, while Gemma 3-n E4B IT and Phi-3 mini trail, especially on HumanEval." class="post-image" loading="lazy">
<div class="image-alt">Alt text:
Grouped bar chart titled “Benchmark Comparison Across Models.” The x-axis lists seven language models (left → right): Gemma 3-n E4B IT, GPT-4o, Claude 3 Opus, Llama 3.3 70B, Mixtral 8×22B, Llama 3 8B, Phi-3 mini 4B.
For each model there are three adjacent vertical bars:

Model	MMLU Accuracy	MBPP pass@1	HumanEval pass@1
Gemma 3-n E4B IT	~65 %	~64 %	~75 %
GPT-4o	~86 %	~71 %	~86 %
Claude 3 Opus	~89 %	~70 %	~86 %
Llama 3.3 70B	~86 %	~88 %	~88 %
Mixtral 8×22B	~78 %	~64 %	~74 %
Llama 3 8B	~73 %	~73 %	~73 %
Phi-3 mini 4B	~69 %	~70 %	~59 %

The y-axis spans 0 % to 100 %. Taller bars indicate stronger performance; Llama 3.3 70B, GPT-4o, and Claude 3 Opus lead across all three benchmarks, while Gemma 3-n E4B IT and Phi-3 mini trail, especially on HumanEval.</div>
</div>
</div>
</div>