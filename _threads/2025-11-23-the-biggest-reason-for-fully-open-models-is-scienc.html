---
layout: thread
title: "the biggest reason for fully open models is science, and the downstream effects"
date: 2025-11-23 15:20:33 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m6cmfbsjxk2d
likes: 32
reposts: 0
post_count: 2
summary: "the biggest reason for fully open models is science, and the downstream effects  1. rebuild it, but with your own domain-specific mid-training data 2...."
similar:
  - url: "/threads/2025-07-08-smollm3-a-highly-detailed-look-into-modern-model/"
    title: "SmolLM3: a highly detailed look into modern model training"
  - url: "/threads/2025-05-14-attentioninfluence-for-pretraining-data-selection/"
    title: "AttentionInfluence: for pretraining data selection"
  - url: "/threads/2025-07-27-great-paper-alert-gspo-group-sequence-policy-op/"
    title: "ðŸš¨Great Paper AlertðŸš¨ GSPO (Group Sequence Policy Optimization)"
---
<div class="thread-post">
<div class="post-text">the biggest reason for fully open models is science, and the downstream effects<br><br>1. rebuild it, but with your own domain-specific mid-training data<br>2. try methods out on several snapshots <br>3. attribute answers to specific documents in the training dataset<br>4. â€¦</div>
<a href="https://bsky.app/profile/did:plc:kft6lu4trxowqmter2b6vg6z/post/3m6azvrbd3c26" class="post-quote" target="_blank" rel="noopener">
<div class="quote-header">
<img src="https://cdn.bsky.app/img/avatar/plain/did:plc:kft6lu4trxowqmter2b6vg6z/bafkreiewl57f52tt6jrd7gtn75edweos7z6bjxsqhottxw4l7zme6o55ma@jpeg" alt="" class="quote-avatar">
<span class="quote-author">Simon Willison</span>
<span class="quote-handle">@simonwillison.net</span>
</div>
<div class="quote-text">Olmo 3 is notable as a "fully open" LLM - all of the training data is published, plus complete details on how the training process was run. I tried out the 32B thinking model and the 7B instruct models, + thoughts on why transparent training data is so important simonwillison.net/2025/Nov/22/...</div>

</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>32</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">on #3, this paper uses a method where they can directly attribute specific documents from the pretraining dataset<br><br>they used it to show that LLMs do in fact learn procedures, not just autocomplete. But you could take this so much further with Olmo3<br><br><a href="https://arxiv.org/abs/2411.12580" target="_blank" rel="noopener">arxiv.org/abs/2411.12580</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreibpbau2lgq3vorcargsekp7wx7musae6epjhdz3iacdhi62ihj3fy@jpeg" alt="A comic-style infographic titled â€œTHE AI CHEFâ€™S â€˜PROCEDURALâ€™ SECRET: AN ATTRIBUTION ANALOGY.â€ It uses a robot chef baking a soufflÃ© to explain how attribution and gradient-based tracing in AI works. The diagram proceeds left to right in five labeled steps.

â¸»

1. THE TASK (REASONING)

A friendly robot chef stands in a kitchen, holding up a perfectly baked soufflÃ©. A math bubble shows x + 2y = 10 as an analogy for solving a problem.
Caption: AI Chef (LLM) solves a problem (bakes a soufflÃ©).

â¸»

2. THE â€œFINGERPRINTâ€ (GRADIENT)

Close-up of the robot whisking batter. A glowing network of abstract swirls appears over the bowl.
Caption: We record the exact, unique actions & â€œeffortâ€ (Gradient) used for this specific soufflÃ©.

â¸»

3. THE â€œBRAIN MAPâ€ (EK/FAC)

The robot stands before floating diagram bubbles labeled Whisking Techniques, Aeration Physics, Heat Transfer, Simplified Linkages.
Caption: We use a simplified map of how the chef connects concepts (Hessian/EK-FAC approximation).

â¸»

4. THE LIBRARY MATCH (ATTRIBUTION)

The robot enters a vast library with floor-to-ceiling bookshelves. A giant glowing fingerprint projection shines onto one shelf as the robot scans for the best match.
Caption: We scan the entire â€œcookbook libraryâ€ (pre-training data) to find which bookâ€™s instructions best match the fingerprint via the brain map.

â¸»

5. THE RESULT: PROCEDURAL KNOWLEDGE

The robot chef proudly holds a glowing lightbulb while a book opens nearby with a concept diagram. A large reference book beside him is titled â€œTHE PHYSICS OF FOAMS & AERATION (NOT a SoufflÃ© Recipe Book!)â€
Caption: We find the source was NOT a recipe, but a foundational PRINCIPLE (procedural knowledge) applied to a new task.

â¸»

Overall, the image uses the story of baking a soufflÃ© to explain how AI models trace reasoning: capturing gradients, mapping conceptual relations, searching training data, and revealing underlying procedural knowledge rather than direct memorization." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>15</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>