---
layout: thread
title: "HRM analysis by @dorialexander.bsky.social "
date: 2025-08-04 01:40:37 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lvk2swwus22q
likes: 37
reposts: 7
post_count: 2
summary: "HRM analysis by @dorialexander.bsky.social   the actual shocking parts:  * it doesn’t overfit * ARC-AGI is only hard for language models  i think we’l..."
similar:
  - url: "/threads/2025-07-27-hrm-hierarchical-reasoning-model-ngl-this-sounds/"
    title: "HRM: Hierarchical Reasoning Model"
  - url: "/threads/2025-11-29-this-whole-smol-model-thing-that-dorialexanderbs/"
    title: "this whole smol model thing that @dorialexander.bsky.social started is remind..."
  - url: "/threads/2025-11-11-80-layers-for-those-not-paying-attention-doria/"
    title: "80 layers — for those not paying attention, @dorialexander.bsky.social has be..."
---
<div class="thread-post">
<div class="post-text">HRM analysis by <a href="https://bsky.app/profile/did:plc:vg3thtvfbgfrr3u6pf6hy3yk" target="_blank" rel="noopener">@dorialexander.bsky.social</a> <br><br>the actual shocking parts:<br><br>* it doesn’t overfit<br>* ARC-AGI is only hard for language models<br><br>i think we’ll be seeing more of HRM</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>37</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="time-elapsed">16 hours later</div>
<div class="post-text">another take, even more depth & nuance<br><br><a href="https://x.com/n8programs/status/1952392992536375572?s=46&t=ftkDjGBpGPr2-yTN2CCUYg" target="_blank" rel="noopener">x.com/n8programs/s...</a></div>
<div class="post-images multiple">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreib4du26yhkscqvtfgojelj23xtrwojjqymetnfmo33r4ty74j64lq@jpeg" alt="N8
N8 Programs & @N8Programs
My take on HRM (after reading the paper): its very beautifully mathematically and the architecture is somewhat vindicated by the experiments they perform. The architecture itself is a work of art - they ingeniously incorporate early-stopping (via Q-learning), avoid BPTT via a shallow approximation that's sparsely sampled every few steps of the model, etc.
The results they achieve on Sudoku & Maze-Solving are extremely impressive given the sparse amount of training data, and indicates their architecture has amazing sample efficiency
- its inductive biases (low-frequency & high-frequency representations to iteratively solve a problem) are conducive to great generalization.
The one red flag is the ARC-AGI methodology - they attach a &quot;learnable special token that represents the puzzle it belongs to&quot; to each training example - and the training examples are drawn from the train and evaluation sets. As I understand it, they hold out the singular example" class="post-image" loading="lazy">
<div class="image-alt">N8
N8 Programs & @N8Programs
My take on HRM (after reading the paper): its very beautifully mathematically and the architecture is somewhat vindicated by the experiments they perform. The architecture itself is a work of art - they ingeniously incorporate early-stopping (via Q-learning), avoid BPTT via a shallow approximation that's sparsely sampled every few steps of the model, etc.
The results they achieve on Sudoku & Maze-Solving are extremely impressive given the sparse amount of training data, and indicates their architecture has amazing sample efficiency
- its inductive biases (low-frequency & high-frequency representations to iteratively solve a problem) are conducive to great generalization.
The one red flag is the ARC-AGI methodology - they attach a &quot;learnable special token that represents the puzzle it belongs to&quot; to each training example - and the training examples are drawn from the train and evaluation sets. As I understand it, they hold out the singular example</div>
</div>
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidyjl5pwldqr7ez2v4mflrsintsolxf65lxoaf6nbasqg32ayh66u@jpeg" alt="drawn from the train and evaluation sets. As I understand it, they hold out the singular example for each eval task that the model would normally be expected to perform few-shot inference on.
Instead, at evaluation time, the model uses the learnable special token to recall the appropriate task and apply it to the input grid. This superficially is very distinct from ARC - memorizing a bag of functions and recalling one with a pre-determined ID seems antithetical to few-shot generalization.
However, they only use 960 examples - essentially the amount the original ARC + ConceptArc. This means many of their task IDs are learned from 3-4 examples during their very limited pre-training phase. There's no reason why, instead of setting the evaluation task ids in pretraining, they couldn't have a special novel task id they finetune at test time. Given say, three in-context examples, they could augment them into a 20-30 example train set and test-time tune a new task id on those examples. Then use that id for evaluation. Because their method has been demonstrated to have such extreme generalization from limited samples, this would likely yield a similar result, and would be fully in the spirit of ARC: generalizing at test-time from a" class="post-image" loading="lazy">
<div class="image-alt">drawn from the train and evaluation sets. As I understand it, they hold out the singular example for each eval task that the model would normally be expected to perform few-shot inference on.
Instead, at evaluation time, the model uses the learnable special token to recall the appropriate task and apply it to the input grid. This superficially is very distinct from ARC - memorizing a bag of functions and recalling one with a pre-determined ID seems antithetical to few-shot generalization.
However, they only use 960 examples - essentially the amount the original ARC + ConceptArc. This means many of their task IDs are learned from 3-4 examples during their very limited pre-training phase. There's no reason why, instead of setting the evaluation task ids in pretraining, they couldn't have a special novel task id they finetune at test time. Given say, three in-context examples, they could augment them into a 20-30 example train set and test-time tune a new task id on those examples. Then use that id for evaluation. Because their method has been demonstrated to have such extreme generalization from limited samples, this would likely yield a similar result, and would be fully in the spirit of ARC: generalizing at test-time from a</div>
</div>
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreievsjyqw3732og7cpkn2ekisfr7g4gp3zndsv6bl3w5khv4c7faam@jpeg" alt="use that id for evaluation. Because their method has been demonstrated to have such extreme generalization from limited samples, this would likely yield a similar result, and would be fully in the spirit of ARC: generalizing at test-time from a limited set of examples (and would follow established ARC trends of test-time training).
So all in all - definitely not BS! Very serious exploration of a two-level recurrent transformer with extreme sample efficiency. Methodological issue on ARC that could be corrected fairly easily. Very exciting paper overall!
One note however:
It's important not to confuse the HRM (which is as of now, is a small architecture used to train networks that generalize across narrow problems) with LLMs in comparisons - one is a very specialized experimental tool, and the other is a behemoth that supports every linguistic task under the sun. HRMs, like AlphaGo or AlexNet or any pre-GPT neural network, are black boxes that know nothing of language and solve their tasks entirely in latent space (which was the goal of the paper authors!). This means they should never be compared one-to-one with large" class="post-image" loading="lazy">
<div class="image-alt">use that id for evaluation. Because their method has been demonstrated to have such extreme generalization from limited samples, this would likely yield a similar result, and would be fully in the spirit of ARC: generalizing at test-time from a limited set of examples (and would follow established ARC trends of test-time training).
So all in all - definitely not BS! Very serious exploration of a two-level recurrent transformer with extreme sample efficiency. Methodological issue on ARC that could be corrected fairly easily. Very exciting paper overall!
One note however:
It's important not to confuse the HRM (which is as of now, is a small architecture used to train networks that generalize across narrow problems) with LLMs in comparisons - one is a very specialized experimental tool, and the other is a behemoth that supports every linguistic task under the sun. HRMs, like AlphaGo or AlexNet or any pre-GPT neural network, are black boxes that know nothing of language and solve their tasks entirely in latent space (which was the goal of the paper authors!). This means they should never be compared one-to-one with large</div>
</div>
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreibbeoe67ulii7uu26ufu2fomgku7vp7ycqrt3ahczsef7zydvissu@jpeg" alt="of the paper authors!). This means they should never be compared one-to-one with large language models or treated as a potential replacement. Of course, since HRM is seq-to-seq and could be updated to support causal masking - you could use it to solve the objective of next-token prediction! But that would be an entirely different experiment, and take us back to the space of linguistic reasoning, which the authors wanted to avoid." class="post-image" loading="lazy">
<div class="image-alt">of the paper authors!). This means they should never be compared one-to-one with large language models or treated as a potential replacement. Of course, since HRM is seq-to-seq and could be updated to support causal masking - you could use it to solve the objective of next-token prediction! But that would be an entirely different experiment, and take us back to the space of linguistic reasoning, which the authors wanted to avoid.</div>
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>4</span>
</div>
</div>