---
layout: thread
title: "not enough is being said about DeepSeek’s multi token prediction (MTP)"
date: 2024-12-26 23:54:09 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3leaobzje6k2t
likes: 52
reposts: 6
post_count: 2
summary: "not enough is being said about DeepSeek’s multi token prediction (MTP)  They were able to get sonnet-level performance with less data than llama 3.3 7..."
similar:
  - url: "/threads/2024-11-13-this-feels-like-a-very-big-deal-2-trillion-tokens/"
    title: "this feels like a very big deal"
  - url: "/threads/2025-07-06-new-3-token-attention-reduces-pre-training-data-re/"
    title: "new 3-token attention reduces pre-training data requirements"
  - url: "/threads/2025-07-17-openai-livestream-announcing-chatgpt-agent-succe/"
    title: "OpenAI Livestream: Announcing ChatGPT Agent"
---
<div class="thread-post">
<div class="post-text">not enough is being said about DeepSeek’s multi token prediction (MTP)<br><br>They were able to get sonnet-level performance with less data than llama 3.3 70B<br><br>Does that mean scaling isn’t over? (if we can just be more efficient) Also, does that mean we can train a LLM fully on properly licensed content?</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreidg5y7qjjufr62ztyqnjxdv4jb6modxg64osmfunbujbcsho4kxoi@jpeg" alt="" class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>52</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>6</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">the vibe i get is that MTP is mainly just useful during training, but it’s a huge signal booster that lets the model pickup on the real signal in the text a lot faster</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>4</span>
</div>
</div>