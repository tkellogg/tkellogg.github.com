---
layout: thread
title: "Opus 4.5"
date: 2025-11-24 20:09:30 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m6fmyvasqk26
likes: 36
reposts: 2
post_count: 5
summary: "Opus 4.5  Now 1/3rd the cost, and SOTA in programming   Like Gemini 3 Pro, people note that it can see a lot deeper into tough problems. That big mode..."
similar:
  - url: "/threads/2025-08-05-opus-41-released-wwwanthropiccomnewsclaude/"
    title: "Opus 4.1 Released"
  - url: "/threads/2025-11-24-anthropic-has-no-competitors-because-nobody-else/"
    title: "Anthropic has no competitors, because nobody else sells Claude"
  - url: "/threads/2025-12-02-claude-opus-soul-document-opus-45-was-indeed/"
    title: "Claude Opus ‚Äúsoul document‚Äù"
---
<div class="thread-post">
<div class="post-text">Opus 4.5<br><br>Now 1/3rd the cost, and SOTA in programming <br><br>Like Gemini 3 Pro, people note that it can see a lot deeper into tough problems. That big model smell..<br><br><a href="https://www.anthropic.com/news/claude-opus-4-5" target="_blank" rel="noopener">www.anthropic.com/news/claude-...</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreicfmyronocsu7y23eecnbdqmxf3qjlfrm65f3du4jdicx7drxnhjq@jpeg" alt="A clean bar chart titled ‚ÄúSoftware engineering ‚Äî SWE-bench Verified (n=500)‚Äù showing accuracy scores (in percent) for six models. Each bar is labeled and color-coded, with values displayed above the bars. From left to right:
	‚Ä¢	Opus 4.5 ‚Äî tall orange bar at 80.9% (highest in the chart)
	‚Ä¢	Sonnet 4.5 ‚Äî yellow bar at 77.2%
	‚Ä¢	Opus 4.1 ‚Äî blue bar at 74.5%
	‚Ä¢	Gemini 3 Pro ‚Äî light gray bar at 76.2%
	‚Ä¢	GPT-5.1-Codex-Max ‚Äî light gray bar at 77.9%
	‚Ä¢	GPT-5.1 ‚Äî light gray bar at 76.3%

The y-axis shows Accuracy (%), ranging from 70 to 82, and the x-axis lists the model names along the bottom." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>36</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Benchmarks<br><br>- they compared against Gemini 3 üëç<br>- they showed a decent number of benchmarks<br>- It *actually* does well compared against Gemini</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreifuqa5o42ysmwttvuudlyqaqitw2yfk4uqeftthz4emldpspb3cze@jpeg" alt="A table comparing multiple AI models across a wide range of benchmarks. The Opus 4.5 column is highlighted in a light red tint. Each row lists a task category on the left, followed by performance percentages for each model: Opus 4.5, Sonnet 4.5, Opus 4.1, Gemini 3 Pro, and GPT-5.1 (with some GPT-5.1 Codex-Max scores shown in smaller text).

Rows and values:

‚∏ª

Agentic coding ‚Äî SWE-bench Verified
	‚Ä¢	Opus 4.5: 80.9%
	‚Ä¢	Sonnet 4.5: 77.2%
	‚Ä¢	Opus 4.1: 74.5%
	‚Ä¢	Gemini 3 Pro: 76.2%
	‚Ä¢	GPT-5.1: 76.3% (77.9% Codex-Max)

Agentic terminal coding ‚Äî Terminal-bench 2.0
	‚Ä¢	Opus 4.5: 59.3%
	‚Ä¢	Sonnet 4.5: 50.0%
	‚Ä¢	Opus 4.1: 46.5%
	‚Ä¢	Gemini 3 Pro: 54.2%
	‚Ä¢	GPT-5.1: 47.6% (58.1% Codex-Max)

Agentic tool use ‚Äî tz-bench

Retail / Telecom results:

Retail:
	‚Ä¢	Opus 4.5: 88.9%
	‚Ä¢	Sonnet 4.5: 86.2%
	‚Ä¢	Opus 4.1: 86.8%
	‚Ä¢	Gemini 3 Pro: 85.3%
	‚Ä¢	GPT-5.1: ‚Äî

Telecom:
	‚Ä¢	Opus 4.5: 98.2%
	‚Ä¢	Sonnet 4.5: 98.0%
	‚Ä¢	Opus 4.1: 71.5%
	‚Ä¢	Gemini 3 Pro: 98.0%
	‚Ä¢	GPT-5.1: ‚Äî

Scaled tool use ‚Äî MCP Atlas
	‚Ä¢	Opus 4.5: 62.3%
	‚Ä¢	Sonnet 4.5: 43.8%
	‚Ä¢	Opus 4.1: 40.9%
	‚Ä¢	Gemini 3 Pro: ‚Äî
	‚Ä¢	GPT-5.1: ‚Äî

Computer use ‚Äî OSWorld
	‚Ä¢	Opus 4.5: 66.3%
	‚Ä¢	Sonnet 4.5: 61.4%
	‚Ä¢	Opus 4.1: 44.4%
	‚Ä¢	Gemini 3 Pro: ‚Äî
	‚Ä¢	GPT-5.1: ‚Äî

Novel problem solving ‚Äî ARC-AGI-2 (Verified)
	‚Ä¢	Opus 4.5: 37.6%
	‚Ä¢	Sonnet 4.5: 13.6%
	‚Ä¢	Opus 4.1: ‚Äî
	‚Ä¢	Gemini 3 Pro: 31.1%
	‚Ä¢	GPT-5.1: 17.6%

Graduate-level reasoning ‚Äî GPQA Diamond
	‚Ä¢	Opus 4.5: 87.0%
	‚Ä¢	Sonnet 4.5: 83.4%
	‚Ä¢	Opus 4.1: 81.0%
	‚Ä¢	Gemini 3 Pro: 91.9% (highest in row)
	‚Ä¢	GPT-5.1: 88.1%

Visual reasoning ‚Äî MMMU (validation)
	‚Ä¢	Opus 4.5: 80.7%
	‚Ä¢	Sonnet 4.5: 77.8%
	‚Ä¢	Opus 4.1: 77.1%
	‚Ä¢	Gemini 3 Pro: ‚Äî
	‚Ä¢	GPT-5.1: 85.4% (highest in row)

Multilingual Q&A ‚Äî MMMU
	‚Ä¢	Opus 4.5: 90.8%
	‚Ä¢	Sonnet 4.5: 89.1%
	‚Ä¢	Opus 4.1: 89.5%
	‚Ä¢	Gemini 3 Pro: 91.8%
	‚Ä¢	GPT-5.1: 91.0%

‚∏ª
" class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>13</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">system card<br><br><a href="https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf" target="_blank" rel="noopener">assets.anthropic.com/m/64823ba748...</a><br><br>oh, high alignment and low rates of concerning behavior? sounds like bliss</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreibn46ghbzyi4xnmhkzosum5yybn7rpqqcxs5sko6gevm2mcpf4gni@jpeg" alt="Our safety evaluations found that, overall, Claude Opus 4.5 showed low rates of concerning behavior. We consider it to be our best-aligned frontier model yet, and likely the best-aligned frontier model in the Al industry to date. Nevertheless, there are many" class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Anthropic has been exploring new ways of burning tokens<br><br>put differently: you can get Opus high now!</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreickpjhwzxds2kjo3lfjd4vdczrskg7q6rxmdu33z4l75baiiyl65u@jpeg" alt="A line chart titled ‚ÄúSoftware engineering with effort controls ‚Äî SWE-bench Verified (n=500)‚Äù showing how accuracy changes with output token count for two models: Opus 4.5 (orange) and Sonnet 4.5 (yellow).

Opus 4.5 (orange line with three labeled points):
	‚Ä¢	Low effort: ~4,000 tokens, 75% accuracy
	‚Ä¢	Medium effort: ~6,000 tokens, 78% accuracy
	‚Ä¢	High effort: ~12,000 tokens, 81% accuracy

A smooth upward-sloping line connects these three points, showing that accuracy increases as output tokens increase.

Sonnet 4.5 (yellow single point):
	‚Ä¢	A single dot around 22,000 tokens and ~77% accuracy, with no line connecting it.

Axes & Notes:
	‚Ä¢	Y-axis: Accuracy (%) from 70 to 85
	‚Ä¢	X-axis: Output tokens from 0 to 25,000
	‚Ä¢	Caption notes that measurements were done with extended thinking off, and that turning it on increases output tokens by +5.4% on average.

Legend:
	‚Ä¢	‚¨§ Opus 4.5 (orange)
	‚Ä¢	‚¨§ Sonnet 4.5 (yellow)

The chart illustrates how higher ‚Äúeffort‚Äù (i.e., more output tokens) boosts software-engineering accuracy, especially for Opus 4.5." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>8</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">Opus 4.5 *just barely* missed scaling concern level 4<br><br>lets dive in, what does level 4 look like? (chatgpt summary there on right)<br><br>üò≥</div>
<div class="post-images multiple">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreic5qeaxrh52bji6eabbt6xuj2emkhkdr6mbesryvbrpyjeui6ygs4@jpeg" alt="1.2.4 Conclusions
Our determination is that Claude Opus 4.5 does not cross either the AI R&D-4 or CBRN-4 capability threshold. However, confidently ruling out these thresholds is becoming increasingly difficult. This is in part because the model is approaching or surpassing high levels of capability in our &quot;rule-out&quot; evaluations (early proxies of each threshold). In addition, parts of the Al R&D-4 and CBRN-4 thresholds have fundamental epistemic uncertainty or require more sophisticated forms of measurement. We are launching Claude" class="post-image" loading="lazy">
</div>
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreibs4q43gyryaurpyu757lsxlu5tgx7fe7je3ukygqtsjpyufu5vvm@jpeg" alt="1. Al R&D-4
This means the model can fully automate the work of an entry-level, remote-only Al researcher at Anthropic. Hitting this level would imply the model could do substantial autonomous Al research/dev work end-to-end, which raises big
&quot;runaway capability&quot; and misalignment risks.
Anthropic
2. CBRN-4
This means the model could substantially uplift a moderately resourced state
CBRN program (chemical/biological/ radiological/nuclear weapons), e.g., by enabling novel weapon design, big acceleration of processes, or lowering technical barriers. Anthropic
operationalizes this as uplifting a team of entry-level PhD-skill biologists toward world-class state-backed capability.
Anthropic" class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>7</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>