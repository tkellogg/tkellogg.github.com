---
layout: thread
title: "if i could wish something into being — a complete decoupling of LLM knowledge..."
date: 2025-03-18 02:16:46 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3lkmlzmioa22k
likes: 28
reposts: 1
post_count: 4
summary: "if i could wish something into being — a complete decoupling of LLM knowledge vs reasoning   seems like the key would be a “database” model that retur..."
similar:
  - url: "/threads/2025-08-01-persona-vectors-brb-anthropic-just-droppe/"
    title: "Persona Vectors"
  - url: "/threads/2025-07-22-inverse-scaling-of-reasoning-models-a-research-co/"
    title: "Inverse scaling of reasoning models"
  - url: "/threads/2025-08-25-starting-with-k2-several-large-agentic-coding-m/"
    title: "Starting with K2, several large “agentic coding” models weren’t trained as re..."
---
<div class="thread-post">
<div class="post-text">if i could wish something into being — a complete decoupling of LLM knowledge vs reasoning <br><br>seems like the key would be a “database” model that returns queries in vectors, raw information rather than snippets of documents</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>28</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>1</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">the innovation behind such a database would be <br><br>1. most of the n*n calculation is cacheable across requests so multi gigabyte context is feasible <br><br>2. raw vectors include reasoning across docs, it’s raw info inferred from snippets across hundreds of docs</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">on my mind — highly sparse MoE models are hot right now, but they’re lame af. you’re forcibly requiring that 7/8ths of your hardware be idle (or 31/32nds, in the case of R1/V3), which is nuts<br><br>this is the way: dense reasoning models with huge remote async “knowledge” models</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>4</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">and RAG still doesn’t go away, you need it for rapidly fluctuating or highly structured data</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>