---
layout: thread
title: "MiniMax open sources M2"
date: 2025-10-27 11:28:04 +0000
bluesky_url: https://bsky.app/profile/did:plc:ckaz32jwl6t2cno6fmuw2nhn/post/3m46cspajf22z
likes: 34
reposts: 3
post_count: 6
summary: "MiniMax open sources M2  This model has been shaking the benchmarks last week, now that it’s open we see that it’s 230B-A10B and dueling (arguably bea..."
similar:
  - url: "/threads/2025-09-12-its-true-the-last-two-qwens-have-been-beautiful/"
    title: "it’s true, the last two Qwens have been beautiful works of art, until you tal..."
  - url: "/threads/2025-11-22-one-ai-trend-thats-not-fully-baked-but-will-chan/"
    title: "one AI trend that’s not fully baked, but will change a huge amount — auto-com..."
  - url: "/threads/2025-07-11-its-new-entrant-week-today-kimi-k2-an-open-wei/"
    title: "it’s new entrant week! today? Kimi-K2"
---
<div class="thread-post">
<div class="post-text">MiniMax open sources M2<br><br>This model has been shaking the benchmarks last week, now that it’s open we see that it’s 230B-A10B and dueling (arguably beating) Sonnet 4.5 at 8% of the cost<br><br><a href="https://github.com/MiniMax-AI/MiniMax-M2?tab=readme-ov-file" target="_blank" rel="noopener">github.com/MiniMax-AI/M...</a></div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreiajf6etdv2wotnu7plne2flntg5no3z4zaxd4ysaz2igk7i4js3eu@jpeg" alt="Eight side-by-side bar charts (2 rows × 4 columns) comparing models; each bar has a small icon that matches the legend at the bottom.

Top row, left → right within each chart:

SWE-bench Verified — 69.4, 67.8, 68.0, 69.2, 63.8, 77.2, 74.9.
Multi-SWE-Bench — 36.2, 30.6, 30.0, 33.5, 44.3.
Terminal-Bench — 46.3, 37.7, 40.5, 44.5, 25.3, 50.0, 43.8.
ArtifactsBench — 66.8, 55.8, 59.8, 54.2, 57.7, 61.5, 73.0.

Bottom row, left → right within each chart:

T²-Bench — 77.2, 66.7, 75.9, 70.3, 59.2, 84.7, 80.1.
GAIA (text only) — 75.7, 63.5, 71.9, 60.2, 60.2, 71.2, 76.4.
BrowseComp — 44.0, 40.1, 45.1, 14.1, 9.9, 19.6, 54.9.
FinSearchComp-global — 65.5, 26.2, 29.2, 29.5, 42.6, 60.8, 63.9.

Legend (icons → model names):
MiniMax-M2; DeepSeek-V3.2; GLM-4.6; Kimi K2 0905; Gemini 2.5 Pro; Claude Sonnet 4.5; GPT-5 (thinking)." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>34</span>
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M7 7h10v3l4-4-4-4v3H5v6h2V7zm10 10H7v-3l-4 4 4 4v-3h12v-6h-2v4z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">why build a model? vertical integration <br><br>seems like US models actually do work fine, they’re just too expensive <br><br>also, a little bit of an admission that Chinese models are a little wonky</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreieuaj2agmfvuhrdpuyvhdjpjpk43zsz4lyxfejejoxtmfqxf3nvmi@jpeg" alt="Our team has been building a variety of Agents to help tackle the challenges of our company's rapid growth. These Agents are beginning to complete increasingly complex tasks, from analyzing online data and researching technical issues to daily programming, processing user feedback, and even screening HR resumes. These Agents, working alongside our team, are driving the company's development, building an Al-native organization that is evolving from developing AGI to advancing together with AGI. We have an ever-stronger conviction that AGI is a force of production, and Agents are an excellent vehicle for it, representing an evolution from the simple Q&A of conversational assistants to the independent completion of complex tasks by Agents.
However, we found that no single model could fully meet our needs for these Agents. The challenge lies in finding a model that strikes the right balance between performance, price, and inference speed-an almost &quot;impossible triangle.&quot; The best overseas models offer good performance but are very expensive and relatively slow. Domestic models are cheaper, but there is a gap in their performance and speed.
This has led to existing Agent products often being very expensive or slow to achieve good results. For instance, many Agent subscriptions cost tens or even hundreds of dollars per month, and completing a single task can often take hours." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>4</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">how they’re thinking about model architecture</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreigtdwgo3mzxhkl6uhxjo2suxpqdacco7hdrucloajb2qki2lsyzfu@jpeg" alt="* Why activation size matters
By maintaining activations around 10B, the plan → act → verify loop in the agentic workflow is streamlined, improving responsiveness and reducing compute overhead:
• Faster feedback cycles in compile-run-test and browse-retrieve-cite chains.
• More concurrent runs on the same budget for regression suites and multi-seed explorations.
• Simpler capacity planning with smaller per-request memory and steadier tail latency.
In short: 10B activations = responsive
agent loops + better unit economics." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>2</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">this is another model in fp8 format, definitely a trend toward lower precision <br><br>gpt-oss was in fp4, but several others have been in fp8. i’m a bit surprised that attention is in fp8, but the model does seem to work well<br><br>1M context (if you can pay for the KV cache)</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>3</span>
</div>
</div>
<div class="thread-post">
<div class="post-text">gents, i think we’ve reached it</div>
<div class="post-images single">
<div class="post-image-container">
<img src="https://cdn.bsky.app/img/feed_thumbnail/plain/did:plc:ckaz32jwl6t2cno6fmuw2nhn/bafkreih4zl4jdjr6t5a6atg2lxqhyo6i7ioqwpcvcxlatqpsa6rnwp7uoi@jpeg" alt="doomslide & @doomslide • 13h
Personally I draw the line at superduperintelligence." class="post-image" loading="lazy">
</div>
</div>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>9</span>
</div>
</div>
<div class="thread-post">
<div class="time-elapsed">1 hour later</div>
<div class="post-text"><a href="https://bsky.app/profile/dorialexander.bsky.social/post/3m46fgjnz6s2d" target="_blank" rel="noopener">bsky.app/profile/dori...</a></div>
<a href="https://bsky.app/profile/did:plc:vg3thtvfbgfrr3u6pf6hy3yk/post/3m46fgjnz6s2d" class="post-quote" target="_blank" rel="noopener">
<div class="quote-header">
<img src="https://cdn.bsky.app/img/avatar/plain/did:plc:vg3thtvfbgfrr3u6pf6hy3yk/bafkreibs7ii3ttxu37wi2ljpo3hsj56qityzvgihl4vw6q7uknu3q73aly@jpeg" alt="" class="quote-avatar">
<span class="quote-author">Alexander Doria</span>
<span class="quote-handle">@dorialexander.bsky.social</span>
</div>
<div class="quote-text">New MiniMax release today. Still waiting for the tech report, but the blogpost makes a compelling case for mastering the technology end-to-end to get actual agentic automation www.minimax.io/news/minimax...</div>
<div class="quote-images"><img src="https://cdn.bsky.app/img/feed_fullsize/plain/did:plc:vg3thtvfbgfrr3u6pf6hy3yk/bafkreifv2gftvswk3mjuhfdqo2xdlir6q2l6svxhcow5afrmdvozup57da@jpeg" alt="" class="quote-image" loading="lazy"></div>
</a>
<div class="post-stats">
<span class="stat-item"><svg class="stat-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>2</span>
</div>
</div>